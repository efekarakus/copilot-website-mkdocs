{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"docs/credentials/","text":"This section explains our recommendations around credentials to provide the best experience with the AWS Copilot CLI. Application credentials Copilot uses the AWS credentials from the default credential provider chain to store and look up your application's metadata : which services and environments belong to it. Tip We recommend using a named profile to store your application's credentials. The most convenient way is having the [default] profile point to your application's credentials: # ~/.aws/credentials [default] aws_access_key_id = AKIAIOSFODNN7EXAMPLE aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY # ~/.aws/config [default] region = us-west-2 Alternatively, you can set the AWS_PROFILE environment variable to point to a different named profile. For example, we can have a [my-app] profile that can be used for your Copilot application instead of the [default] profile. # ~/.aws/config [my-app] credential_process = /opt/bin/awscreds-custom --username helen region = us-west-2 # Then you can run your Copilot commands leveraging the alternative profile: $ export AWS_PROFILE = my-app $ copilot deploy Caution We do not recommend using the environment variables: AWS_ACCESS_KEY_ID , AWS_SECRET_ACCESS_KEY , AWS_SESSION_TOKEN directly to look up your application's metadata because if they're overridden or expired then Copilot will not be able to look up your services or environments. To learn more on all the supported config file settings: Configuration and credential file settings . Environment credentials Copilot environments can be created in separate AWS accounts and regions than your application. While initializing an environment, Copilot will prompt you if you'd like to enter temporary credentials or a named profile to create your environment: $ copilot env init Name: prod-iad Which credentials would you like to use to create prod-iad? > Enter temporary credentials > [ profile default ] > [ profile test ] > [ profile prod-iad ] > [ profile prod-pdx ] Unlike the Application credentials section, the AWS credentials for an environment are only needed for creation or deletion. Therefore, it's safe to use the values from temporary environment variables. Copilot prompts or takes the credentials as flags because the default chain is reserved for your application credentials.","title":"Credentials"},{"location":"docs/credentials/#application-credentials","text":"Copilot uses the AWS credentials from the default credential provider chain to store and look up your application's metadata : which services and environments belong to it. Tip We recommend using a named profile to store your application's credentials. The most convenient way is having the [default] profile point to your application's credentials: # ~/.aws/credentials [default] aws_access_key_id = AKIAIOSFODNN7EXAMPLE aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY # ~/.aws/config [default] region = us-west-2 Alternatively, you can set the AWS_PROFILE environment variable to point to a different named profile. For example, we can have a [my-app] profile that can be used for your Copilot application instead of the [default] profile. # ~/.aws/config [my-app] credential_process = /opt/bin/awscreds-custom --username helen region = us-west-2 # Then you can run your Copilot commands leveraging the alternative profile: $ export AWS_PROFILE = my-app $ copilot deploy Caution We do not recommend using the environment variables: AWS_ACCESS_KEY_ID , AWS_SECRET_ACCESS_KEY , AWS_SESSION_TOKEN directly to look up your application's metadata because if they're overridden or expired then Copilot will not be able to look up your services or environments. To learn more on all the supported config file settings: Configuration and credential file settings .","title":"Application credentials"},{"location":"docs/credentials/#environment-credentials","text":"Copilot environments can be created in separate AWS accounts and regions than your application. While initializing an environment, Copilot will prompt you if you'd like to enter temporary credentials or a named profile to create your environment: $ copilot env init Name: prod-iad Which credentials would you like to use to create prod-iad? > Enter temporary credentials > [ profile default ] > [ profile test ] > [ profile prod-iad ] > [ profile prod-pdx ] Unlike the Application credentials section, the AWS credentials for an environment are only needed for creation or deletion. Therefore, it's safe to use the values from temporary environment variables. Copilot prompts or takes the credentials as flags because the default chain is reserved for your application credentials.","title":"Environment credentials"},{"location":"docs/getting-started/","text":"AWS Copilot makes it easy to deploy your containers to AWS in just a few steps. In this tutorial we\u2019re going to do just that - we\u2019re going to deploy a sample front end service that you can visit in your browser. While we\u2019ll be using a sample static website in this example, you can use AWS Copilot to build and deploy any container app with a Dockerfile. After we get your service all set up, we\u2019ll show you how to delete the resources Copilot created to avoid charges. Sound fun? Let\u2019s do it! Step 1: Download & Configure AWS Copilot You\u2019ll need a few things to use AWS Copilot - the AWS Copilot binary, AWS CLI, Docker Desktop and AWS credentials. Follow our instructions here on how to set up and configure all these tools. Make sure that you have a default profile! Run aws configure to set one up! Step 2: Download some code to deploy In this example, we\u2019ll be using a sample app that\u2019s just a simple static website - but if you already have something you\u2019d like to deploy, just open your terminal and cd into your Dockerfile\u2019s directory. Otherwise you can just clone our sample repository. In your terminal, copy and paste this code. This will clone our sample app and change directories to it. $ git clone https://github.com/aws-samples/aws-copilot-sample-service example $ cd example Step 3: Setting up our app Now this is where the fun starts! We have our service code and our Dockerfile and we want to get it deployed to AWS. Let\u2019s have AWS Copilot help us do just that! From within your code directory run: $ copilot init Step 4: Answer a few questions The next thing we\u2019re going to do is answer a few questions from Copilot. Copilot will use these questions to help us choose the best AWS infrastructure for your service. There\u2019s only a few so let\u2019s go through them: \u201cWhat would you like to name your application\u201d - an application is a collection of services. In this example we\u2019ll only have one service in our app, but if you wanted to have a multi-service app, Copilot makes that easy. Let\u2019s call this app example-app . \u201cWhich service type best represents your service's architecture?\u201d - Copilot is asking us what we want our service to do - do we want it to service traffic? Do we want it to be a private backend service? For us, we want our app to be accessible from the web, so let's hit enter and select Load Balanced Web Service . \u201cWhat do you want to name this Load Balanced Web Service?\u201d - now what should we call our service in our app? Be as creative as you want - but I recommend naming this service front-end . \u201cWhich Dockerfile would you like to use for front-end?\u201d - go ahead and choose the default Dockerfile here. This is the service that Copilot will build and deploy for you. Once you choose your Dockerfile, Copilot will start setting up the AWS infrastructure to manage your service. Step 5: Deploy your service Once Copilot finishes setting up the infrastructure to manage your app, you\u2019ll be asked if you want to deploy your service to a test environment type yes. Now we can wait a few minutes \u23f3 while Copilot sets up all the resources needed to run your service. After all the infrastructure for your service is set up, Copilot will build your image and push it to Amazon ECR, and start deploying to Amazon ECS. After your deployment completes your service will be up and running on AWS Fargate and Copilot will print a link to the URL \ud83c\udf89! Cleaning up Now that you've deployed your service, let's go ahead and run copilot app delete - this will delete all the resources Copilot set up for your application, including your ECS Service and the ECR Repository. To delete everything run: $ copilot app delete --env-profiles test = default Congratulations! Congratulations! You have learned how to setup, deploy, and delete your container application to Amazon ECS using AWS Copilot. AWS Copilot is a command line tool that helps you develop, release and operate your container apps on AWS. We hope you had fun deploying your app. Ready to dive deeper into AWS Copilot and learn how to build and manage production ready container apps on AWS? Check out the Developing section in the sidebar.","title":"Getting Started"},{"location":"docs/getting-started/#step-1-download-configure-aws-copilot","text":"You\u2019ll need a few things to use AWS Copilot - the AWS Copilot binary, AWS CLI, Docker Desktop and AWS credentials. Follow our instructions here on how to set up and configure all these tools. Make sure that you have a default profile! Run aws configure to set one up!","title":"Step 1: Download &amp; Configure AWS Copilot"},{"location":"docs/getting-started/#step-2-download-some-code-to-deploy","text":"In this example, we\u2019ll be using a sample app that\u2019s just a simple static website - but if you already have something you\u2019d like to deploy, just open your terminal and cd into your Dockerfile\u2019s directory. Otherwise you can just clone our sample repository. In your terminal, copy and paste this code. This will clone our sample app and change directories to it. $ git clone https://github.com/aws-samples/aws-copilot-sample-service example $ cd example","title":"Step 2: Download some code to deploy"},{"location":"docs/getting-started/#step-3-setting-up-our-app","text":"Now this is where the fun starts! We have our service code and our Dockerfile and we want to get it deployed to AWS. Let\u2019s have AWS Copilot help us do just that! From within your code directory run: $ copilot init","title":"Step 3: Setting up our app"},{"location":"docs/getting-started/#step-4-answer-a-few-questions","text":"The next thing we\u2019re going to do is answer a few questions from Copilot. Copilot will use these questions to help us choose the best AWS infrastructure for your service. There\u2019s only a few so let\u2019s go through them: \u201cWhat would you like to name your application\u201d - an application is a collection of services. In this example we\u2019ll only have one service in our app, but if you wanted to have a multi-service app, Copilot makes that easy. Let\u2019s call this app example-app . \u201cWhich service type best represents your service's architecture?\u201d - Copilot is asking us what we want our service to do - do we want it to service traffic? Do we want it to be a private backend service? For us, we want our app to be accessible from the web, so let's hit enter and select Load Balanced Web Service . \u201cWhat do you want to name this Load Balanced Web Service?\u201d - now what should we call our service in our app? Be as creative as you want - but I recommend naming this service front-end . \u201cWhich Dockerfile would you like to use for front-end?\u201d - go ahead and choose the default Dockerfile here. This is the service that Copilot will build and deploy for you. Once you choose your Dockerfile, Copilot will start setting up the AWS infrastructure to manage your service.","title":"Step 4: Answer a few questions"},{"location":"docs/getting-started/#step-5-deploy-your-service","text":"Once Copilot finishes setting up the infrastructure to manage your app, you\u2019ll be asked if you want to deploy your service to a test environment type yes. Now we can wait a few minutes \u23f3 while Copilot sets up all the resources needed to run your service. After all the infrastructure for your service is set up, Copilot will build your image and push it to Amazon ECR, and start deploying to Amazon ECS. After your deployment completes your service will be up and running on AWS Fargate and Copilot will print a link to the URL \ud83c\udf89!","title":"Step 5: Deploy your service"},{"location":"docs/getting-started/#cleaning-up","text":"Now that you've deployed your service, let's go ahead and run copilot app delete - this will delete all the resources Copilot set up for your application, including your ECS Service and the ECR Repository. To delete everything run: $ copilot app delete --env-profiles test = default","title":"Cleaning up"},{"location":"docs/getting-started/#congratulations","text":"Congratulations! You have learned how to setup, deploy, and delete your container application to Amazon ECS using AWS Copilot. AWS Copilot is a command line tool that helps you develop, release and operate your container apps on AWS. We hope you had fun deploying your app. Ready to dive deeper into AWS Copilot and learn how to build and manage production ready container apps on AWS? Check out the Developing section in the sidebar.","title":"Congratulations!"},{"location":"docs/installing/","text":"You can install AWS Copilot through Homebrew or by downloading the binaries directly. Homebrew \ud83c\udf7b brew install aws/tap/copilot-cli Manually Copy and paste the command into your terminal. macOS Command to install curl -Lo /usr/local/bin/copilot https://github.com/aws/copilot-cli/releases/download/v0.4.0/copilot-darwin-v0.4.0 && chmod +x /usr/local/bin/copilot && copilot --help Linux Command to install curl -Lo /usr/local/bin/copilot https://github.com/aws/copilot-cli/releases/download/v0.4.0/copilot-linux-v0.4.0 && chmod +x /usr/local/bin/copilot && copilot --help","title":"Installing"},{"location":"docs/installing/#homebrew","text":"brew install aws/tap/copilot-cli","title":"Homebrew \ud83c\udf7b"},{"location":"docs/installing/#manually","text":"Copy and paste the command into your terminal. macOS Command to install curl -Lo /usr/local/bin/copilot https://github.com/aws/copilot-cli/releases/download/v0.4.0/copilot-darwin-v0.4.0 && chmod +x /usr/local/bin/copilot && copilot --help Linux Command to install curl -Lo /usr/local/bin/copilot https://github.com/aws/copilot-cli/releases/download/v0.4.0/copilot-linux-v0.4.0 && chmod +x /usr/local/bin/copilot && copilot --help","title":"Manually"},{"location":"docs/overview/","text":"Welcome to the AWS Copilot CLI \ud83c\udf89 The Copilot CLI is a tool for developers to build, release, and operate production ready containerized applications on Amazon ECS and AWS Fargate. From getting started, pushing to staging and releasing to production, Copilot can help manage the entire lifecycle of your application development. Installing You can install AWS Copilot through Homebrew or by downloading the binaries directly. If you don't want to use Homebrew, you can install manually . $ brew install aws/tap/copilot-cli","title":"Overview"},{"location":"docs/overview/#installing","text":"You can install AWS Copilot through Homebrew or by downloading the binaries directly. If you don't want to use Homebrew, you can install manually . $ brew install aws/tap/copilot-cli","title":"Installing"},{"location":"docs/commands/app-delete/","text":"app delete $ copilot app delete [ flags ] What does it do? copilot app delete deletes all resources associated with an application. What are the flags? --env-profiles stringToString Optional. Environments and the profile to use to delete the environment. ( default []) -h, --help help for delete --yes Skips confirmation prompt. Examples Force delete the application with environments \"test\" and \"prod\". $ copilot app delete --yes --env-profiles test = default,prod = prod-profile","title":"app delete"},{"location":"docs/commands/app-delete/#app-delete","text":"$ copilot app delete [ flags ]","title":"app delete"},{"location":"docs/commands/app-delete/#what-does-it-do","text":"copilot app delete deletes all resources associated with an application.","title":"What does it do?"},{"location":"docs/commands/app-delete/#what-are-the-flags","text":"--env-profiles stringToString Optional. Environments and the profile to use to delete the environment. ( default []) -h, --help help for delete --yes Skips confirmation prompt.","title":"What are the flags?"},{"location":"docs/commands/app-delete/#examples","text":"Force delete the application with environments \"test\" and \"prod\". $ copilot app delete --yes --env-profiles test = default,prod = prod-profile","title":"Examples"},{"location":"docs/commands/app-init/","text":"app init $ copilot app init [ name ] [ flags ] What does it do? copilot app init creates a new application within the directory that will contain your service(s). After you answer the questions, the CLI creates AWS Identity and Access Management roles to manage the release infrastructure for your services. You'll also see a new sub-directory created under your working directory: copilot/ . The copilot directory will hold the manifest files and additional infrastructure for your services. Typically, you don't need to run app init ( init does all the same work) unless you want to use a custom domain name or AWS tags. What are the flags? Like all commands in the Copilot CLI, if you don't provide required flags, we'll prompt you for all the information we need to get you going. You can skip the prompts by providing information via flags: --domain string Optional. Your existing custom domain name. -h, --help help for init --resource-tags stringToString Optional. Labels with a key and value separated with commas. Allows you to categorize resources. ( default []) The --domain flag allows you to specify a domain name registered with Amazon Route 53 in your app's account. This will allow all the services in your app to share the same domain name. You'll be able to access your services at: https://{svcName}.{envName}.{appName}.{domain} The --resource-tags flags allows you to add your custom tags to all the resources in your app. For example: $ copilot app init --resource-tags department=MyDept,team=MyTeam Examples Create a new application named \"my-app\". $ copilot app init my-app Create a new application with an existing domain name in Amazon Route53. $ copilot app init --domain example.com Create a new application with resource tags. $ copilot app init --resource-tags department = MyDept,team = MyTeam What does it look like?","title":"app init"},{"location":"docs/commands/app-init/#app-init","text":"$ copilot app init [ name ] [ flags ]","title":"app init"},{"location":"docs/commands/app-init/#what-does-it-do","text":"copilot app init creates a new application within the directory that will contain your service(s). After you answer the questions, the CLI creates AWS Identity and Access Management roles to manage the release infrastructure for your services. You'll also see a new sub-directory created under your working directory: copilot/ . The copilot directory will hold the manifest files and additional infrastructure for your services. Typically, you don't need to run app init ( init does all the same work) unless you want to use a custom domain name or AWS tags.","title":"What does it do?"},{"location":"docs/commands/app-init/#what-are-the-flags","text":"Like all commands in the Copilot CLI, if you don't provide required flags, we'll prompt you for all the information we need to get you going. You can skip the prompts by providing information via flags: --domain string Optional. Your existing custom domain name. -h, --help help for init --resource-tags stringToString Optional. Labels with a key and value separated with commas. Allows you to categorize resources. ( default []) The --domain flag allows you to specify a domain name registered with Amazon Route 53 in your app's account. This will allow all the services in your app to share the same domain name. You'll be able to access your services at: https://{svcName}.{envName}.{appName}.{domain} The --resource-tags flags allows you to add your custom tags to all the resources in your app. For example: $ copilot app init --resource-tags department=MyDept,team=MyTeam","title":"What are the flags?"},{"location":"docs/commands/app-init/#examples","text":"Create a new application named \"my-app\". $ copilot app init my-app Create a new application with an existing domain name in Amazon Route53. $ copilot app init --domain example.com Create a new application with resource tags. $ copilot app init --resource-tags department = MyDept,team = MyTeam","title":"Examples"},{"location":"docs/commands/app-init/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/app-ls/","text":"app ls $ copilot app ls [ flags ] What does it do? copilot app ls lists all the Copilot applications in your account. What are the flags? -h, --help help for ls Examples List all the applications in your account and region. $ copilot app ls What does it look like?","title":"app ls"},{"location":"docs/commands/app-ls/#app-ls","text":"$ copilot app ls [ flags ]","title":"app ls"},{"location":"docs/commands/app-ls/#what-does-it-do","text":"copilot app ls lists all the Copilot applications in your account.","title":"What does it do?"},{"location":"docs/commands/app-ls/#what-are-the-flags","text":"-h, --help help for ls","title":"What are the flags?"},{"location":"docs/commands/app-ls/#examples","text":"List all the applications in your account and region. $ copilot app ls","title":"Examples"},{"location":"docs/commands/app-ls/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/app-show/","text":"app show $ copilot app show [ flags ] What does it do? copilot app show shows configuration, environments and services for an application. What are the flags? -h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the application. Examples Shows info about the application \"my-app\". $ copilot app show -n my-app What does it look like?","title":"app show"},{"location":"docs/commands/app-show/#app-show","text":"$ copilot app show [ flags ]","title":"app show"},{"location":"docs/commands/app-show/#what-does-it-do","text":"copilot app show shows configuration, environments and services for an application.","title":"What does it do?"},{"location":"docs/commands/app-show/#what-are-the-flags","text":"-h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the application.","title":"What are the flags?"},{"location":"docs/commands/app-show/#examples","text":"Shows info about the application \"my-app\". $ copilot app show -n my-app","title":"Examples"},{"location":"docs/commands/app-show/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/completion/","text":"completion $ copilot completion [shell] [flags] What does it do? copilot completion prints shell completion code for bash or zsh. The code must be evaluated to provide interactive completion of commands. See the help menu for instructions on how to setup auto-completion for your respective shell. What are the flags? -h, --help help for completion Examples Install zsh completion. $ source < ( copilot completion zsh ) $ copilot completion zsh > \" ${ fpath [1] } /_copilot\" # to autoload on startup Install bash completion on macOS using homebrew. $ brew install bash-completion # if running 3.2 $ brew install bash-completion@2 # if running Bash 4.1+ $ copilot completion bash > /usr/local/etc/bash_completion.d Install bash completion on linux $ source < ( copilot completion bash ) $ copilot completion bash > copilot.sh $ sudo mv copilot.sh /etc/bash_completion.d/copilot","title":"completion"},{"location":"docs/commands/completion/#completion","text":"$ copilot completion [shell] [flags]","title":"completion"},{"location":"docs/commands/completion/#what-does-it-do","text":"copilot completion prints shell completion code for bash or zsh. The code must be evaluated to provide interactive completion of commands. See the help menu for instructions on how to setup auto-completion for your respective shell.","title":"What does it do?"},{"location":"docs/commands/completion/#what-are-the-flags","text":"-h, --help help for completion","title":"What are the flags?"},{"location":"docs/commands/completion/#examples","text":"Install zsh completion. $ source < ( copilot completion zsh ) $ copilot completion zsh > \" ${ fpath [1] } /_copilot\" # to autoload on startup Install bash completion on macOS using homebrew. $ brew install bash-completion # if running 3.2 $ brew install bash-completion@2 # if running Bash 4.1+ $ copilot completion bash > /usr/local/etc/bash_completion.d Install bash completion on linux $ source < ( copilot completion bash ) $ copilot completion bash > copilot.sh $ sudo mv copilot.sh /etc/bash_completion.d/copilot","title":"Examples"},{"location":"docs/commands/deploy/","text":"copilot deploy $ copilot deploy This command is an alias for copilot svc deploy .","title":"deploy"},{"location":"docs/commands/deploy/#copilot-deploy","text":"$ copilot deploy This command is an alias for copilot svc deploy .","title":"copilot deploy"},{"location":"docs/commands/docs/","text":"docs $ copilot docs [ flags ] What does it do? copilot docs open the copilot docs in your browser. What are the flags? -h, --help help for docs","title":"docs"},{"location":"docs/commands/docs/#docs","text":"$ copilot docs [ flags ]","title":"docs"},{"location":"docs/commands/docs/#what-does-it-do","text":"copilot docs open the copilot docs in your browser.","title":"What does it do?"},{"location":"docs/commands/docs/#what-are-the-flags","text":"-h, --help help for docs","title":"What are the flags?"},{"location":"docs/commands/env-delete/","text":"env delete $ copilot env delete [ flags ] What does it do? copilot env delete deletes an environment from your application. If there are running applications in your environment, you first need to run copilot svc delete . After you answer the questions, you should see the AWS CloudFormation stack for your environment gone. What are the flags? -h, --help help for delete -n, --name string Name of the environment. --profile string Name of the profile. --yes Skips confirmation prompt. -a, --app string Name of the application. Examples Delete the \"test\" environment. $ copilot env delete --name test --profile default Delete the \"test\" environment without prompting. $ copilot env delete --name test --profile default --yes","title":"env delete"},{"location":"docs/commands/env-delete/#env-delete","text":"$ copilot env delete [ flags ]","title":"env delete"},{"location":"docs/commands/env-delete/#what-does-it-do","text":"copilot env delete deletes an environment from your application. If there are running applications in your environment, you first need to run copilot svc delete . After you answer the questions, you should see the AWS CloudFormation stack for your environment gone.","title":"What does it do?"},{"location":"docs/commands/env-delete/#what-are-the-flags","text":"-h, --help help for delete -n, --name string Name of the environment. --profile string Name of the profile. --yes Skips confirmation prompt. -a, --app string Name of the application.","title":"What are the flags?"},{"location":"docs/commands/env-delete/#examples","text":"Delete the \"test\" environment. $ copilot env delete --name test --profile default Delete the \"test\" environment without prompting. $ copilot env delete --name test --profile default --yes","title":"Examples"},{"location":"docs/commands/env-init/","text":"env init $ copilot env init [ flags ] What does it do? copilot env init creates a new environment where your services will live. After you answer the questions, the CLI creates the common infrastructure that's shared between your services such as a VPC, an Application Load Balancer, and an ECS Cluster. Additionally, you can customize Copilot environment by either configuring the default environment resources or importing existing resources for your environment. You create environments using a named profile to specify which AWS Account and Region you'd like the environment to be in. What are the flags? Like all commands in the AWS Copilot CLI, if you don't provide required flags, we'll prompt you for all the information we need to get you going. You can skip the prompts by providing information via flags: Common Flags --aws-access-key-id string Optional. An AWS access key. --aws-secret-access-key string Optional. An AWS secret access key. --aws-session-token string Optional. An AWS session token for temporary credentials. --default-config Optional. Skip prompting and use default environment configuration. -n, --name string Name of the environment. --prod If the environment contains production services. --profile string Name of the profile. --region string Optional. An AWS region where the environment will be created. Import Existing Resources Flags --import-private-subnets strings Optional. Use existing private subnet IDs. --import-public-subnets strings Optional. Use existing public subnet IDs. --import-vpc-id string Optional. Use an existing VPC ID. Configure Default Resources Flags --override-private-cidrs strings Optional. CIDR to use for private subnets (default 10.0.2.0/24,10.0.3.0/24). --override-public-cidrs strings Optional. CIDR to use for public subnets (default 10.0.0.0/24,10.0.1.0/24). --override-vpc-cidr ipNet Optional. Global CIDR to use for VPC (default 10.0.0.0/16). Global Flags -a, --app string Name of the application. Examples Creates a test environment in your \"default\" AWS profile using default config. $ copilot env init --name test --profile default --default-config Creates a prod-iad environment using your \"prod-admin\" AWS profile using existing VPC. $ copilot env init --name prod-iad --profile prod-admin --prod \\ --import-vpc-id vpc-099c32d2b98cdcf47 \\ --import-public-subnets subnet-013e8b691862966cf,subnet -014661ebb7ab8681a \\ --import-private-subnets subnet-055fafef48fb3c547,subnet-00c9e76f288363e7f What does it look like?","title":"env init"},{"location":"docs/commands/env-init/#env-init","text":"$ copilot env init [ flags ]","title":"env init"},{"location":"docs/commands/env-init/#what-does-it-do","text":"copilot env init creates a new environment where your services will live. After you answer the questions, the CLI creates the common infrastructure that's shared between your services such as a VPC, an Application Load Balancer, and an ECS Cluster. Additionally, you can customize Copilot environment by either configuring the default environment resources or importing existing resources for your environment. You create environments using a named profile to specify which AWS Account and Region you'd like the environment to be in.","title":"What does it do?"},{"location":"docs/commands/env-init/#what-are-the-flags","text":"Like all commands in the AWS Copilot CLI, if you don't provide required flags, we'll prompt you for all the information we need to get you going. You can skip the prompts by providing information via flags: Common Flags --aws-access-key-id string Optional. An AWS access key. --aws-secret-access-key string Optional. An AWS secret access key. --aws-session-token string Optional. An AWS session token for temporary credentials. --default-config Optional. Skip prompting and use default environment configuration. -n, --name string Name of the environment. --prod If the environment contains production services. --profile string Name of the profile. --region string Optional. An AWS region where the environment will be created. Import Existing Resources Flags --import-private-subnets strings Optional. Use existing private subnet IDs. --import-public-subnets strings Optional. Use existing public subnet IDs. --import-vpc-id string Optional. Use an existing VPC ID. Configure Default Resources Flags --override-private-cidrs strings Optional. CIDR to use for private subnets (default 10.0.2.0/24,10.0.3.0/24). --override-public-cidrs strings Optional. CIDR to use for public subnets (default 10.0.0.0/24,10.0.1.0/24). --override-vpc-cidr ipNet Optional. Global CIDR to use for VPC (default 10.0.0.0/16). Global Flags -a, --app string Name of the application.","title":"What are the flags?"},{"location":"docs/commands/env-init/#examples","text":"Creates a test environment in your \"default\" AWS profile using default config. $ copilot env init --name test --profile default --default-config Creates a prod-iad environment using your \"prod-admin\" AWS profile using existing VPC. $ copilot env init --name prod-iad --profile prod-admin --prod \\ --import-vpc-id vpc-099c32d2b98cdcf47 \\ --import-public-subnets subnet-013e8b691862966cf,subnet -014661ebb7ab8681a \\ --import-private-subnets subnet-055fafef48fb3c547,subnet-00c9e76f288363e7f","title":"Examples"},{"location":"docs/commands/env-init/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/env-ls/","text":"env ls $ copilot env ls [ flags ] What does it do? copilot env ls lists all the environments in your application. What are the flags? -h, --help help for ls --json Optional. Outputs in JSON format. -a, --app string Name of the application. You can use the --json flag if you'd like to programmatically parse the results. Examples Lists all the environments for the frontend application. $ copilot env ls -a frontend What does it look like?","title":"env ls"},{"location":"docs/commands/env-ls/#env-ls","text":"$ copilot env ls [ flags ]","title":"env ls"},{"location":"docs/commands/env-ls/#what-does-it-do","text":"copilot env ls lists all the environments in your application.","title":"What does it do?"},{"location":"docs/commands/env-ls/#what-are-the-flags","text":"-h, --help help for ls --json Optional. Outputs in JSON format. -a, --app string Name of the application. You can use the --json flag if you'd like to programmatically parse the results.","title":"What are the flags?"},{"location":"docs/commands/env-ls/#examples","text":"Lists all the environments for the frontend application. $ copilot env ls -a frontend","title":"Examples"},{"location":"docs/commands/env-ls/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/env-show/","text":"env show $ copilot env show [ flags ] What does it do? copilot env show shows displays information about a particular environment, including: The region and account the environment is in Whether or not the environment is production The services currently deployed in the environment The tags associated with that environment You can optionally pass in a --resources flag which will include the AWS resources associated specifically with the environment. What are the flags? -h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the environment. --resources Optional. Show the resources in your environment. You can use the --json flag if you'd like to programmatically parse the results. Examples Shows info about the environment \"test\". $ copilot env show -n test","title":"env show"},{"location":"docs/commands/env-show/#env-show","text":"$ copilot env show [ flags ]","title":"env show"},{"location":"docs/commands/env-show/#what-does-it-do","text":"copilot env show shows displays information about a particular environment, including: The region and account the environment is in Whether or not the environment is production The services currently deployed in the environment The tags associated with that environment You can optionally pass in a --resources flag which will include the AWS resources associated specifically with the environment.","title":"What does it do?"},{"location":"docs/commands/env-show/#what-are-the-flags","text":"-h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the environment. --resources Optional. Show the resources in your environment. You can use the --json flag if you'd like to programmatically parse the results.","title":"What are the flags?"},{"location":"docs/commands/env-show/#examples","text":"Shows info about the environment \"test\". $ copilot env show -n test","title":"Examples"},{"location":"docs/commands/init/","text":"init $ copilot init What does it do? copilot init is your starting point if you want to deploy your container app on Amazon ECS. Run it within a directory with your Dockerfile, and init will ask you questions about your application so we can get it up and running quickly. After you answer all the questions, copilot init will set up an ECR repository for you and ask you if you'd like to deploy. If you opt to deploy, it'll create a new test environment (complete with a networking stack and roles), build your Dockerfile, push it to Amazon ECR, and deploy your service. If you have an existing app, and want to add another service to that app, you can run copilot init - and you'll be prompted to select an existing app to add your app to. What are the flags? Like all commands in the copilot CLI, if you don't provide required flags, we'll prompt you for all the information we need to get you going. You can skip the prompts by providing information via flags: -a, --app string Name of the application. --deploy Deploy your service to a \"test\" environment. -d, --dockerfile string Path to the Dockerfile. -h, --help help for init --port uint16 Optional. The port on which your service listens. --profile string Name of the profile. ( default \"default\" ) -s, --svc string Name of the service. -t, --svc-type string Type of service to create. Must be one of: \"Load Balanced Web Service\" , \"Backend Service\" --tag string Optional. The service ' s image tag. What does it look like?","title":"init"},{"location":"docs/commands/init/#init","text":"$ copilot init","title":"init"},{"location":"docs/commands/init/#what-does-it-do","text":"copilot init is your starting point if you want to deploy your container app on Amazon ECS. Run it within a directory with your Dockerfile, and init will ask you questions about your application so we can get it up and running quickly. After you answer all the questions, copilot init will set up an ECR repository for you and ask you if you'd like to deploy. If you opt to deploy, it'll create a new test environment (complete with a networking stack and roles), build your Dockerfile, push it to Amazon ECR, and deploy your service. If you have an existing app, and want to add another service to that app, you can run copilot init - and you'll be prompted to select an existing app to add your app to.","title":"What does it do?"},{"location":"docs/commands/init/#what-are-the-flags","text":"Like all commands in the copilot CLI, if you don't provide required flags, we'll prompt you for all the information we need to get you going. You can skip the prompts by providing information via flags: -a, --app string Name of the application. --deploy Deploy your service to a \"test\" environment. -d, --dockerfile string Path to the Dockerfile. -h, --help help for init --port uint16 Optional. The port on which your service listens. --profile string Name of the profile. ( default \"default\" ) -s, --svc string Name of the service. -t, --svc-type string Type of service to create. Must be one of: \"Load Balanced Web Service\" , \"Backend Service\" --tag string Optional. The service ' s image tag.","title":"What are the flags?"},{"location":"docs/commands/init/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/pipeline-delete/","text":"pipeline delete $ copilot pipeline delete [ flags ] What does it do? copilot pipeline delete deletes the pipeline associated with your workspace. What are the flags? --delete-secret Deletes AWS Secrets Manager secret associated with a pipeline source repository. -h, --help help for delete --yes Skips confirmation prompt. Examples Delete the pipeline associated with your workspace. $ copilot pipeline delete","title":"pipeline delete"},{"location":"docs/commands/pipeline-delete/#pipeline-delete","text":"$ copilot pipeline delete [ flags ]","title":"pipeline delete"},{"location":"docs/commands/pipeline-delete/#what-does-it-do","text":"copilot pipeline delete deletes the pipeline associated with your workspace.","title":"What does it do?"},{"location":"docs/commands/pipeline-delete/#what-are-the-flags","text":"--delete-secret Deletes AWS Secrets Manager secret associated with a pipeline source repository. -h, --help help for delete --yes Skips confirmation prompt.","title":"What are the flags?"},{"location":"docs/commands/pipeline-delete/#examples","text":"Delete the pipeline associated with your workspace. $ copilot pipeline delete","title":"Examples"},{"location":"docs/commands/pipeline-init/","text":"pipeline init $ copilot pipeline init [ flags ] What does it do? copilot pipeline init creates a pipeline manifest for the services in your workspace, using the environments associated with the application. What are the flags? -e, --environments strings Environments to add to the pipeline. -b, --git-branch string Branch used to trigger your pipeline. -t, --github-access-token string GitHub personal access token for your repository. -u, --github-url string GitHub repository URL for your service. -h, --help help for init Examples Create a pipeline for the services in your workspace. $ copilot pipeline init \\ --github-url https://github.com/gitHubUserName/myFrontendApp.git \\ --github-access-token file://myGitHubToken \\ --environments \"test,prod\"","title":"pipeline init"},{"location":"docs/commands/pipeline-init/#pipeline-init","text":"$ copilot pipeline init [ flags ]","title":"pipeline init"},{"location":"docs/commands/pipeline-init/#what-does-it-do","text":"copilot pipeline init creates a pipeline manifest for the services in your workspace, using the environments associated with the application.","title":"What does it do?"},{"location":"docs/commands/pipeline-init/#what-are-the-flags","text":"-e, --environments strings Environments to add to the pipeline. -b, --git-branch string Branch used to trigger your pipeline. -t, --github-access-token string GitHub personal access token for your repository. -u, --github-url string GitHub repository URL for your service. -h, --help help for init","title":"What are the flags?"},{"location":"docs/commands/pipeline-init/#examples","text":"Create a pipeline for the services in your workspace. $ copilot pipeline init \\ --github-url https://github.com/gitHubUserName/myFrontendApp.git \\ --github-access-token file://myGitHubToken \\ --environments \"test,prod\"","title":"Examples"},{"location":"docs/commands/pipeline-show/","text":"pipeline show $ copilot pipeline show [ flags ] What does it do? copilot pipeline show shows configuration information about a deployed pipeline for an application, including the account, region, and stages. What are the flags? -a, --app string Name of the application. -h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the pipeline. --resources Optional. Show the resources in your pipeline. Examples Shows info about the pipeline in the \"myapp\" application. $ copilot pipeline show --app myapp --resources What does it look like?","title":"pipeline show"},{"location":"docs/commands/pipeline-show/#pipeline-show","text":"$ copilot pipeline show [ flags ]","title":"pipeline show"},{"location":"docs/commands/pipeline-show/#what-does-it-do","text":"copilot pipeline show shows configuration information about a deployed pipeline for an application, including the account, region, and stages.","title":"What does it do?"},{"location":"docs/commands/pipeline-show/#what-are-the-flags","text":"-a, --app string Name of the application. -h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the pipeline. --resources Optional. Show the resources in your pipeline.","title":"What are the flags?"},{"location":"docs/commands/pipeline-show/#examples","text":"Shows info about the pipeline in the \"myapp\" application. $ copilot pipeline show --app myapp --resources","title":"Examples"},{"location":"docs/commands/pipeline-show/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/pipeline-status/","text":"pipeline status $ copilot pipeline status [ flags ] What does it do? copilot pipeline status shows the status of the stages in a deployed pipeline. What are the flags? -a, --app string Name of the application. -h, --help help for status --json Optional. Outputs in JSON format. -n, --name string Name of the pipeline. Examples Shows status of the pipeline \"pipeline-myapp-myrepo\". $ copilot pipeline status -n pipeline-myapp-myrepo What does it look like?","title":"pipeline status"},{"location":"docs/commands/pipeline-status/#pipeline-status","text":"$ copilot pipeline status [ flags ]","title":"pipeline status"},{"location":"docs/commands/pipeline-status/#what-does-it-do","text":"copilot pipeline status shows the status of the stages in a deployed pipeline.","title":"What does it do?"},{"location":"docs/commands/pipeline-status/#what-are-the-flags","text":"-a, --app string Name of the application. -h, --help help for status --json Optional. Outputs in JSON format. -n, --name string Name of the pipeline.","title":"What are the flags?"},{"location":"docs/commands/pipeline-status/#examples","text":"Shows status of the pipeline \"pipeline-myapp-myrepo\". $ copilot pipeline status -n pipeline-myapp-myrepo","title":"Examples"},{"location":"docs/commands/pipeline-status/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/pipeline-update/","text":"pipeline update $ copilot pipeline update [ flags ] What does it do? copilot pipeline update deploys a pipeline for the services in your workspace, using the environments associated with the application from a pipeline manifest. What are the flags? -h, --help help for update --yes Skips confirmation prompt. Examples Deploys an updated pipeline for the services in your workspace. $ copilot pipeline update","title":"pipeline update"},{"location":"docs/commands/pipeline-update/#pipeline-update","text":"$ copilot pipeline update [ flags ]","title":"pipeline update"},{"location":"docs/commands/pipeline-update/#what-does-it-do","text":"copilot pipeline update deploys a pipeline for the services in your workspace, using the environments associated with the application from a pipeline manifest.","title":"What does it do?"},{"location":"docs/commands/pipeline-update/#what-are-the-flags","text":"-h, --help help for update --yes Skips confirmation prompt.","title":"What are the flags?"},{"location":"docs/commands/pipeline-update/#examples","text":"Deploys an updated pipeline for the services in your workspace. $ copilot pipeline update","title":"Examples"},{"location":"docs/commands/storage-init/","text":"storage init $ copilot storage init What does it do? copilot storage init creates a new storage resource attached to one of your services, accessible from inside your service container via a friendly environment variable. You can specify either S3 or DynamoDB as the resource type. After running this command, the CLI creates an addons subdirectory inside your copilot/service directory if it does not exist. When you run copilot svc deploy , your newly initialized storage resource is created in the environment you're deploying to. By default, only the service you specify during storage init will have access to that storage resource. What are the flags? Required Flags -n, --name string Name of the storage resource to create. -t, --storage-type string Type of storage to add. Must be one of: \"DynamoDB\" , \"S3\" -s, --svc string Name of the service to associate with storage. DynamoDB Flags --lsi stringArray Optional. Attribute to use as an alternate sort key. May be specified up to 5 times. Must be of the format '<keyName>:<dataType>' . --no-lsi Optional. Don 't ask about configuring alternate sort keys. --no-sort Optional. Skip configuring sort keys. --partition-key string Partition key for the DDB table. Must be of the format ' <keyName>:<dataType> '. --sort-key string Optional. Sort key for the DDB table. Must be of the format ' <keyName>:<dataType> ' . How can I use it? Create an S3 bucket named \"my-bucket\" attached to the \"frontend\" service. $ copilot storage init -n my-bucket -t S3 -s frontend Create a basic DynamoDB table named \"my-table\" attached to the \"frontend\" service with a sort key specified. $ copilot storage init -n my-table -t DynamoDB -s frontend --partition-key Email:S --sort-key UserId:N --no-lsi Create a DynamoDB table with multiple alternate sort keys. $ copilot storage init \\ -n my-table -t DynamoDB -s frontend \\ --partition-key Email:S \\ --sort-key UserId:N \\ --lsi Points:N \\ --lsi Goodness:N What happens under the hood? It then writes a Cloudformation template specifying the S3 bucket or DDB table to the addons dir. When you run copilot svc deploy , the CLI merges this template with all the other templates in the addons directory to create a nested stack associated with your service. This nested stack describes all the additional resources you've associated with that service and is deployed wherever your service is deployed. This means that after running $ copilot storage init -n bucket -t S3 -s fe $ copilot svc deploy -n fe -e test $ copilot svc deploy -n fe -e prod there will be two buckets deployed, one in the \"test\" env and one in the \"prod\" env, accessible only to the \"fe\" service in its respective environment.","title":"storage init"},{"location":"docs/commands/storage-init/#storage-init","text":"$ copilot storage init","title":"storage init"},{"location":"docs/commands/storage-init/#what-does-it-do","text":"copilot storage init creates a new storage resource attached to one of your services, accessible from inside your service container via a friendly environment variable. You can specify either S3 or DynamoDB as the resource type. After running this command, the CLI creates an addons subdirectory inside your copilot/service directory if it does not exist. When you run copilot svc deploy , your newly initialized storage resource is created in the environment you're deploying to. By default, only the service you specify during storage init will have access to that storage resource.","title":"What does it do?"},{"location":"docs/commands/storage-init/#what-are-the-flags","text":"Required Flags -n, --name string Name of the storage resource to create. -t, --storage-type string Type of storage to add. Must be one of: \"DynamoDB\" , \"S3\" -s, --svc string Name of the service to associate with storage. DynamoDB Flags --lsi stringArray Optional. Attribute to use as an alternate sort key. May be specified up to 5 times. Must be of the format '<keyName>:<dataType>' . --no-lsi Optional. Don 't ask about configuring alternate sort keys. --no-sort Optional. Skip configuring sort keys. --partition-key string Partition key for the DDB table. Must be of the format ' <keyName>:<dataType> '. --sort-key string Optional. Sort key for the DDB table. Must be of the format ' <keyName>:<dataType> ' .","title":"What are the flags?"},{"location":"docs/commands/storage-init/#how-can-i-use-it","text":"Create an S3 bucket named \"my-bucket\" attached to the \"frontend\" service. $ copilot storage init -n my-bucket -t S3 -s frontend Create a basic DynamoDB table named \"my-table\" attached to the \"frontend\" service with a sort key specified. $ copilot storage init -n my-table -t DynamoDB -s frontend --partition-key Email:S --sort-key UserId:N --no-lsi Create a DynamoDB table with multiple alternate sort keys. $ copilot storage init \\ -n my-table -t DynamoDB -s frontend \\ --partition-key Email:S \\ --sort-key UserId:N \\ --lsi Points:N \\ --lsi Goodness:N","title":"How can I use it?"},{"location":"docs/commands/storage-init/#what-happens-under-the-hood","text":"It then writes a Cloudformation template specifying the S3 bucket or DDB table to the addons dir. When you run copilot svc deploy , the CLI merges this template with all the other templates in the addons directory to create a nested stack associated with your service. This nested stack describes all the additional resources you've associated with that service and is deployed wherever your service is deployed. This means that after running $ copilot storage init -n bucket -t S3 -s fe $ copilot svc deploy -n fe -e test $ copilot svc deploy -n fe -e prod there will be two buckets deployed, one in the \"test\" env and one in the \"prod\" env, accessible only to the \"fe\" service in its respective environment.","title":"What happens under the hood?"},{"location":"docs/commands/svc-delete/","text":"svc delete $ copilot svc delete [ flags ] What does it do? copilot svc delete deletes all resources associated with your service in a particular environment. What are the flags? -e, --env string Name of the environment. -h, --help help for delete -n, --name string Name of the service. --yes Skips confirmation prompt. Examples Force delete the application with environments \"test\" and \"prod\". $ copilot svc delete --name test --yes","title":"svc delete"},{"location":"docs/commands/svc-delete/#svc-delete","text":"$ copilot svc delete [ flags ]","title":"svc delete"},{"location":"docs/commands/svc-delete/#what-does-it-do","text":"copilot svc delete deletes all resources associated with your service in a particular environment.","title":"What does it do?"},{"location":"docs/commands/svc-delete/#what-are-the-flags","text":"-e, --env string Name of the environment. -h, --help help for delete -n, --name string Name of the service. --yes Skips confirmation prompt.","title":"What are the flags?"},{"location":"docs/commands/svc-delete/#examples","text":"Force delete the application with environments \"test\" and \"prod\". $ copilot svc delete --name test --yes","title":"Examples"},{"location":"docs/commands/svc-deploy/","text":"svc deploy $ copilot svc deploy What does it do? Service deploy takes your local code and configuration and deploys it. The steps involved in service deploy are: Build your local Dockerfile into an image Tag it with the value from --tag or the latest git sha (if you're in a git directory) Push the image to ECR Package your Manifest file and Addons into CloudFormation Create / Update your ECS task-definition and service What are the flags? -e, --env string Name of the environment. -h, --help help for deploy -n, --name string Name of the service. --resource-tags stringToString Optional. Labels with a key and value separated with commas. Allows you to categorize resources. ( default []) --tag string Optional. The service ' s image tag.","title":"svc deploy"},{"location":"docs/commands/svc-deploy/#svc-deploy","text":"$ copilot svc deploy","title":"svc deploy"},{"location":"docs/commands/svc-deploy/#what-does-it-do","text":"Service deploy takes your local code and configuration and deploys it. The steps involved in service deploy are: Build your local Dockerfile into an image Tag it with the value from --tag or the latest git sha (if you're in a git directory) Push the image to ECR Package your Manifest file and Addons into CloudFormation Create / Update your ECS task-definition and service","title":"What does it do?"},{"location":"docs/commands/svc-deploy/#what-are-the-flags","text":"-e, --env string Name of the environment. -h, --help help for deploy -n, --name string Name of the service. --resource-tags stringToString Optional. Labels with a key and value separated with commas. Allows you to categorize resources. ( default []) --tag string Optional. The service ' s image tag.","title":"What are the flags?"},{"location":"docs/commands/svc-init/","text":"svc init $ copilot svc init What does it do? copilot svc init creates a new service to run your code for you. After running this command, the CLI creates sub-directory with your app name in your local copilot directory where you'll find a manifest file . Feel free to update your manifest file to change the default configs for your service. The CLI also sets up an ECR repository with a policy for all environments to be able to pull from it. Then, your service gets registered to AWS System Manager Parameter Store so that the CLI can keep track of your it. After that, if you already have an environment set up, you can run copilot deploy to deploy your service in that environment. What are the flags? Required Flags -d, --dockerfile string Path to the Dockerfile. -n, --name string Name of the service. -t, --svc-type string Type of service to create. Must be one of: \"Load Balanced Web Service\" , \"Backend Service\" Load Balanced Web Service Flags --port uint16 Optional. The port on which your service listens. Backend Service Flags --port uint16 Optional. The port on which your service listens. Each service type has its own optional and required flags besides the common required flags. To create a \"frontend\" load balanced web service you could run: $ copilot svc init --name frontend --app-type \"Load Balanced Web Service\" --dockerfile ./frontend/Dockerfile What does it look like?","title":"svc init"},{"location":"docs/commands/svc-init/#svc-init","text":"$ copilot svc init","title":"svc init"},{"location":"docs/commands/svc-init/#what-does-it-do","text":"copilot svc init creates a new service to run your code for you. After running this command, the CLI creates sub-directory with your app name in your local copilot directory where you'll find a manifest file . Feel free to update your manifest file to change the default configs for your service. The CLI also sets up an ECR repository with a policy for all environments to be able to pull from it. Then, your service gets registered to AWS System Manager Parameter Store so that the CLI can keep track of your it. After that, if you already have an environment set up, you can run copilot deploy to deploy your service in that environment.","title":"What does it do?"},{"location":"docs/commands/svc-init/#what-are-the-flags","text":"Required Flags -d, --dockerfile string Path to the Dockerfile. -n, --name string Name of the service. -t, --svc-type string Type of service to create. Must be one of: \"Load Balanced Web Service\" , \"Backend Service\" Load Balanced Web Service Flags --port uint16 Optional. The port on which your service listens. Backend Service Flags --port uint16 Optional. The port on which your service listens. Each service type has its own optional and required flags besides the common required flags. To create a \"frontend\" load balanced web service you could run: $ copilot svc init --name frontend --app-type \"Load Balanced Web Service\" --dockerfile ./frontend/Dockerfile","title":"What are the flags?"},{"location":"docs/commands/svc-init/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/svc-logs/","text":"svc logs $ copilot svc logs What does it do? copilot svc logs displays the logs of a deployed service. What are the flags? -a, --app string Name of the application. --end-time string Optional. Only return logs before a specific date ( RFC3339 ) . Defaults to all logs. Only one of end-time / follow may be used. -e, --env string Name of the environment. --follow Optional. Specifies if the logs should be streamed. -h, --help help for logs --json Optional. Outputs in JSON format. --limit int Optional. The maximum number of log events returned. ( default 10 ) -n, --name string Name of the service. --since duration Optional. Only return logs newer than a relative duration like 5s, 2m, or 3h. Defaults to all logs. Only one of start-time / since may be used. --start-time string Optional. Only return logs after a specific date ( RFC3339 ) . Defaults to all logs. Only one of start-time / since may be used. --tasks strings Optional. Only return logs from specific task IDs. Examples Displays logs of the service \"my-svc\" in environment \"test\". $ copilot svc logs -n my-svc -e test Displays logs in the last hour. $ copilot svc logs --since 1h Displays logs from 2006-01-02T15:04:05 to 2006-01-02T15:05:05. $ copilot svc logs --start-time 2006-01-02T15:04:05+00:00 --end-time 2006-01-02T15:05:05+00:00","title":"svc logs"},{"location":"docs/commands/svc-logs/#svc-logs","text":"$ copilot svc logs","title":"svc logs"},{"location":"docs/commands/svc-logs/#what-does-it-do","text":"copilot svc logs displays the logs of a deployed service.","title":"What does it do?"},{"location":"docs/commands/svc-logs/#what-are-the-flags","text":"-a, --app string Name of the application. --end-time string Optional. Only return logs before a specific date ( RFC3339 ) . Defaults to all logs. Only one of end-time / follow may be used. -e, --env string Name of the environment. --follow Optional. Specifies if the logs should be streamed. -h, --help help for logs --json Optional. Outputs in JSON format. --limit int Optional. The maximum number of log events returned. ( default 10 ) -n, --name string Name of the service. --since duration Optional. Only return logs newer than a relative duration like 5s, 2m, or 3h. Defaults to all logs. Only one of start-time / since may be used. --start-time string Optional. Only return logs after a specific date ( RFC3339 ) . Defaults to all logs. Only one of start-time / since may be used. --tasks strings Optional. Only return logs from specific task IDs.","title":"What are the flags?"},{"location":"docs/commands/svc-logs/#examples","text":"Displays logs of the service \"my-svc\" in environment \"test\". $ copilot svc logs -n my-svc -e test Displays logs in the last hour. $ copilot svc logs --since 1h Displays logs from 2006-01-02T15:04:05 to 2006-01-02T15:05:05. $ copilot svc logs --start-time 2006-01-02T15:04:05+00:00 --end-time 2006-01-02T15:05:05+00:00","title":"Examples"},{"location":"docs/commands/svc-ls/","text":"svc ls $ copilot svc ls What does it do? copilot svc ls lists all the Copilot services for a particular application. What are the flags? -a, --app string Name of the application. -h, --help help for ls --json Optional. Outputs in JSON format. --local Only show services in the workspace. What does it look like?","title":"svc ls"},{"location":"docs/commands/svc-ls/#svc-ls","text":"$ copilot svc ls","title":"svc ls"},{"location":"docs/commands/svc-ls/#what-does-it-do","text":"copilot svc ls lists all the Copilot services for a particular application.","title":"What does it do?"},{"location":"docs/commands/svc-ls/#what-are-the-flags","text":"-a, --app string Name of the application. -h, --help help for ls --json Optional. Outputs in JSON format. --local Only show services in the workspace.","title":"What are the flags?"},{"location":"docs/commands/svc-ls/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/svc-package/","text":"svc package $ copilot svc package What does it do? copilot svc package produces the CloudFormation template(s) used to deploy a service to an environment. What are the flags? -e, --env string Name of the environment. -h, --help help for package -n, --name string Name of the service. --output-dir string Optional. Writes the stack template and template configuration to a directory. --tag string Optional. The service ' s image tag. Example Write the CloudFormation stack and configuration to a \"infrastructure/\" sub-directory instead of printing. $ copilot svc package -n frontend -e test --output-dir ./infrastructure $ ls ./infrastructure frontend.stack.yml frontend-test.config.yml","title":"svc package"},{"location":"docs/commands/svc-package/#svc-package","text":"$ copilot svc package","title":"svc package"},{"location":"docs/commands/svc-package/#what-does-it-do","text":"copilot svc package produces the CloudFormation template(s) used to deploy a service to an environment.","title":"What does it do?"},{"location":"docs/commands/svc-package/#what-are-the-flags","text":"-e, --env string Name of the environment. -h, --help help for package -n, --name string Name of the service. --output-dir string Optional. Writes the stack template and template configuration to a directory. --tag string Optional. The service ' s image tag.","title":"What are the flags?"},{"location":"docs/commands/svc-package/#example","text":"Write the CloudFormation stack and configuration to a \"infrastructure/\" sub-directory instead of printing. $ copilot svc package -n frontend -e test --output-dir ./infrastructure $ ls ./infrastructure frontend.stack.yml frontend-test.config.yml","title":"Example"},{"location":"docs/commands/svc-show/","text":"svc show $ copilot svc show What does it do? copilot svc show shows info about a deployed service, including endpoints, capacity and related resources per environment. What are the flags? -a, --app string Name of the application. -h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the service. --resources Optional. Show the resources in your service. What does it look like?","title":"svc show"},{"location":"docs/commands/svc-show/#svc-show","text":"$ copilot svc show","title":"svc show"},{"location":"docs/commands/svc-show/#what-does-it-do","text":"copilot svc show shows info about a deployed service, including endpoints, capacity and related resources per environment.","title":"What does it do?"},{"location":"docs/commands/svc-show/#what-are-the-flags","text":"-a, --app string Name of the application. -h, --help help for show --json Optional. Outputs in JSON format. -n, --name string Name of the service. --resources Optional. Show the resources in your service.","title":"What are the flags?"},{"location":"docs/commands/svc-show/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/svc-status/","text":"svc status $ copilot svc status What does it do? copilot svc status shows the health status of a deployed service, including service status, task status, and related CloudWatch alarms. What are the flags? -a, --app string Name of the application. -e, --env string Name of the environment. -h, --help help for status --json Optional. Outputs in JSON format. -n, --name string Name of the service. What does it look like?","title":"svc status"},{"location":"docs/commands/svc-status/#svc-status","text":"$ copilot svc status","title":"svc status"},{"location":"docs/commands/svc-status/#what-does-it-do","text":"copilot svc status shows the health status of a deployed service, including service status, task status, and related CloudWatch alarms.","title":"What does it do?"},{"location":"docs/commands/svc-status/#what-are-the-flags","text":"-a, --app string Name of the application. -e, --env string Name of the environment. -h, --help help for status --json Optional. Outputs in JSON format. -n, --name string Name of the service.","title":"What are the flags?"},{"location":"docs/commands/svc-status/#what-does-it-look-like","text":"","title":"What does it look like?"},{"location":"docs/commands/task-run/","text":"task run $ copilot task run What does it do? Task run deploys and runs one-off tasks. Generally, the steps involved in task run are: 1. Create an ECR repository and a log group for your task 2. Build and push the image to ECR 3. Create or update your ECS task defitinion 4. Run and wait for the tasks to start Info Tasks with the same group name share the same set of resources, including CloudFormation stack, ECR repository, CloudWatch log group and task definition. If the tasks are deployed to a Copilot environment (i.e. by specifying --env ), only public subnets that are created by that environment will be used. The --env flag only works with environments created with v0.3.0 of Copilot or later. Customers using environments created with v0.2.0 or earlier can update their environment manager role with this policy. If using --default and you get an error saying there's no default cluster, run aws ecs create-cluster and then re-run the copilot command. What are the flags? --app string Optional. Name of the application. Cannot be specified with 'default', 'subnets' or 'security-groups' --command string Optional. The command that is passed to \"docker run\" to override the default command. --count int Optional. The number of tasks to set up. (default 1) --cpu int Optional. The number of CPU units to reserve for each task. (default 256) --default Optional. Run tasks in default cluster and default subnets. Cannot be specified with 'app', 'env' or 'subnets'. --dockerfile string Path to the Dockerfile. (default \"Dockerfile\") --env string Optional. Name of the environment. Cannot be specified with 'default', 'subnets' or 'security-groups' --env-vars stringToString Optional. Environment variables specified by key=value separated with commas. (default []) --execution-role string Optional. The role that grants the container agent permission to make AWS API calls. --follow Optional. Specifies if the logs should be streamed. -h, --help help for run --image string Optional. The image to run instead of building a Dockerfile. --memory int Optional. The amount of memory to reserve in MiB for each task. (default 512) --resource-tags stringToString Optional. Labels with a key and value separated with commas. Allows you to categorize resources. (default []) --security-groups strings Optional. The security group IDs for the task to use. Can be specified multiple times. Cannot be specified with 'app' or 'env'. --subnets strings Optional. The subnet IDs for the task to use. Can be specified multiple times. Cannot be specified with 'app', 'env' or 'default'. --tag string Optional. The container image tag in addition to \"latest\". -n, --task-group-name string Optional. The group name of the task. Tasks with the same group name share the same set of resources. --task-role string Optional. The role for the task to use. Example Run a task using your local Dockerfile. You will be prompted to specify a task group name and an environment for the tasks to run in. $ copilot task run --follow Run a task named \"db-migrate\" in the \"test\" environment under the current workspace. $ copilot task run -n db-migrate --env test --follow Run 4 tasks with 2GB memory, an existing image, and a custom task role. $ copilot task run --num 4 --memory 2048 --image=rds-migrate --task-role migrate-role --follow Run a task with environment variables. $ copilot task run --env-vars name=myName,user=myUser Run a task using the current workspace with specific subnets and security groups. $ copilot task run --subnets subnet-123,subnet-456 --security-groups sg-123,sg-456 Run a task with a command. $ copilot task run --command \"python migrate-script.py\"","title":"task run"},{"location":"docs/commands/task-run/#task-run","text":"$ copilot task run","title":"task run"},{"location":"docs/commands/task-run/#what-does-it-do","text":"Task run deploys and runs one-off tasks. Generally, the steps involved in task run are: 1. Create an ECR repository and a log group for your task 2. Build and push the image to ECR 3. Create or update your ECS task defitinion 4. Run and wait for the tasks to start Info Tasks with the same group name share the same set of resources, including CloudFormation stack, ECR repository, CloudWatch log group and task definition. If the tasks are deployed to a Copilot environment (i.e. by specifying --env ), only public subnets that are created by that environment will be used. The --env flag only works with environments created with v0.3.0 of Copilot or later. Customers using environments created with v0.2.0 or earlier can update their environment manager role with this policy. If using --default and you get an error saying there's no default cluster, run aws ecs create-cluster and then re-run the copilot command.","title":"What does it do?"},{"location":"docs/commands/task-run/#what-are-the-flags","text":"--app string Optional. Name of the application. Cannot be specified with 'default', 'subnets' or 'security-groups' --command string Optional. The command that is passed to \"docker run\" to override the default command. --count int Optional. The number of tasks to set up. (default 1) --cpu int Optional. The number of CPU units to reserve for each task. (default 256) --default Optional. Run tasks in default cluster and default subnets. Cannot be specified with 'app', 'env' or 'subnets'. --dockerfile string Path to the Dockerfile. (default \"Dockerfile\") --env string Optional. Name of the environment. Cannot be specified with 'default', 'subnets' or 'security-groups' --env-vars stringToString Optional. Environment variables specified by key=value separated with commas. (default []) --execution-role string Optional. The role that grants the container agent permission to make AWS API calls. --follow Optional. Specifies if the logs should be streamed. -h, --help help for run --image string Optional. The image to run instead of building a Dockerfile. --memory int Optional. The amount of memory to reserve in MiB for each task. (default 512) --resource-tags stringToString Optional. Labels with a key and value separated with commas. Allows you to categorize resources. (default []) --security-groups strings Optional. The security group IDs for the task to use. Can be specified multiple times. Cannot be specified with 'app' or 'env'. --subnets strings Optional. The subnet IDs for the task to use. Can be specified multiple times. Cannot be specified with 'app', 'env' or 'default'. --tag string Optional. The container image tag in addition to \"latest\". -n, --task-group-name string Optional. The group name of the task. Tasks with the same group name share the same set of resources. --task-role string Optional. The role for the task to use.","title":"What are the flags?"},{"location":"docs/commands/task-run/#example","text":"Run a task using your local Dockerfile. You will be prompted to specify a task group name and an environment for the tasks to run in. $ copilot task run --follow Run a task named \"db-migrate\" in the \"test\" environment under the current workspace. $ copilot task run -n db-migrate --env test --follow Run 4 tasks with 2GB memory, an existing image, and a custom task role. $ copilot task run --num 4 --memory 2048 --image=rds-migrate --task-role migrate-role --follow Run a task with environment variables. $ copilot task run --env-vars name=myName,user=myUser Run a task using the current workspace with specific subnets and security groups. $ copilot task run --subnets subnet-123,subnet-456 --security-groups sg-123,sg-456 Run a task with a command. $ copilot task run --command \"python migrate-script.py\"","title":"Example"},{"location":"docs/commands/version/","text":"version $ copilot version [flags] What does it do? copilot version prints the version of the CLI along with the target operating system it was built for. What are the flags? -h, --help help for version","title":"version"},{"location":"docs/commands/version/#version","text":"$ copilot version [flags]","title":"version"},{"location":"docs/commands/version/#what-does-it-do","text":"copilot version prints the version of the CLI along with the target operating system it was built for.","title":"What does it do?"},{"location":"docs/commands/version/#what-are-the-flags","text":"-h, --help help for version","title":"What are the flags?"},{"location":"docs/concepts/applications/","text":"An application is a group of related services, environments, and pipelines. Whether you have one service that does everything or a constelation of micro-services, Copilot organizes them and the environments they're deployed to into an \"application\". Let's walk through an example. We want to build a voting app which needs to collect votes and aggregate the results. To set up our vote app with two services, we can run copilot init twice. The first time we run init , we'll be asked what we should call the application this service will belong to. Since we're trying to build a voting system, we can call our application \"vote\" and our first service \"collector\". The next time we run init , we'll be asked if we want to add our new service to the existing \u201cvote\u201d app, and we\u2019ll name the new service \"aggregator\". Your application configuration (which services and environments belong to it) is stored in your AWS account, so any other users in your account will be able to develop on the \u201cvote\" app as well. This means that you can have a teammate work on one service while you develop the other. Creating an App To set up an application, you can just run copilot init . You'll be asked if you want to set up an app or choose an use app. copilot init Once you've created an application, Copilot stores that application in SSM Parameter store in your AWS account. The account used to set up your application is known as the \"applicaiton account\". This is where your app's configuration lives, and anyone who has access to this account can use this app. All resources created within this application will be tagged with the copilot-app aws resource tag . This helps you know which app resources in your account belong to. The name of your applicaiton has to be unique within your account (even across region). Additional App Configurations You can also provide more granular configuration for your application by running copilot app init . This includes options to: Tag all application, service and environment resources with an additional set of aws resource tags Use a custom domain name for Load Balanced services $ copilot app init \\ --domain my-awesome-app.aws \\ --resource-tags department = MyDept,team = MyTeam App Infrastructure While the bulk of the infrastructure Copilot provisions is specific to an environment and service, there are some application-wide resources, as well. ECR Repositories ECR Repositories are regional resources which store your service images. Each service has its own ECR Repository per region in your app. In the above diagram, the app has several environments spread across three regions. Each of those regions has its own ECR repository for every service in your app. In this case, there are three services. Every time you add a service, we create an ECR Repository in every region. We do this to maintain region isolation (if one region goes down, environments in other region won't be affected) and to reduce cross region data transfer costs. These ECR Repositories all live within your app's account (not the environment accounts) - and have policies which allow your environment accounts to pull from them. Release Infrastructure For every region represented in your app, we create a KMS Key and an S3 bucket. These resources are used by CodePipeline to enable cross region and cross account deployments. All Pipelines in your app share these same resources. Similar to the ECR Repositories, the S3 bucket and KMS keys have policies which allow for all of your environments, even in other accounts, to read encrypted deployment artifacts. This makes your cross-account, cross-region CodePipelines possible. Digging into your App Now that we've set up an app, we can check on it using Copilot. Below are a few common ways to check in on your app. What applications are in my account? To see all the apps in your current account and region you can run copilot app ls . $ copilot app ls vote ecs-kudos What's in my application? Running copilot app show will show you a summary of your application, including all the services and environments in your app. $ copilot app show About Name vote URI vote-app.aws Environments Name AccountID Region test 000000000000 us-east-1 Services Name Type collector Load Balanced Web Service aggregator Backend Service","title":"Applications"},{"location":"docs/concepts/applications/#creating-an-app","text":"To set up an application, you can just run copilot init . You'll be asked if you want to set up an app or choose an use app. copilot init Once you've created an application, Copilot stores that application in SSM Parameter store in your AWS account. The account used to set up your application is known as the \"applicaiton account\". This is where your app's configuration lives, and anyone who has access to this account can use this app. All resources created within this application will be tagged with the copilot-app aws resource tag . This helps you know which app resources in your account belong to. The name of your applicaiton has to be unique within your account (even across region).","title":"Creating an App"},{"location":"docs/concepts/applications/#additional-app-configurations","text":"You can also provide more granular configuration for your application by running copilot app init . This includes options to: Tag all application, service and environment resources with an additional set of aws resource tags Use a custom domain name for Load Balanced services $ copilot app init \\ --domain my-awesome-app.aws \\ --resource-tags department = MyDept,team = MyTeam","title":"Additional App Configurations"},{"location":"docs/concepts/applications/#app-infrastructure","text":"While the bulk of the infrastructure Copilot provisions is specific to an environment and service, there are some application-wide resources, as well.","title":"App Infrastructure"},{"location":"docs/concepts/applications/#ecr-repositories","text":"ECR Repositories are regional resources which store your service images. Each service has its own ECR Repository per region in your app. In the above diagram, the app has several environments spread across three regions. Each of those regions has its own ECR repository for every service in your app. In this case, there are three services. Every time you add a service, we create an ECR Repository in every region. We do this to maintain region isolation (if one region goes down, environments in other region won't be affected) and to reduce cross region data transfer costs. These ECR Repositories all live within your app's account (not the environment accounts) - and have policies which allow your environment accounts to pull from them.","title":"ECR Repositories"},{"location":"docs/concepts/applications/#release-infrastructure","text":"For every region represented in your app, we create a KMS Key and an S3 bucket. These resources are used by CodePipeline to enable cross region and cross account deployments. All Pipelines in your app share these same resources. Similar to the ECR Repositories, the S3 bucket and KMS keys have policies which allow for all of your environments, even in other accounts, to read encrypted deployment artifacts. This makes your cross-account, cross-region CodePipelines possible.","title":"Release Infrastructure"},{"location":"docs/concepts/applications/#digging-into-your-app","text":"Now that we've set up an app, we can check on it using Copilot. Below are a few common ways to check in on your app.","title":"Digging into your App"},{"location":"docs/concepts/applications/#what-applications-are-in-my-account","text":"To see all the apps in your current account and region you can run copilot app ls . $ copilot app ls vote ecs-kudos","title":"What applications are in my account?"},{"location":"docs/concepts/applications/#whats-in-my-application","text":"Running copilot app show will show you a summary of your application, including all the services and environments in your app. $ copilot app show About Name vote URI vote-app.aws Environments Name AccountID Region test 000000000000 us-east-1 Services Name Type collector Load Balanced Web Service aggregator Backend Service","title":"What's in my application?"},{"location":"docs/concepts/environments/","text":"When you first run copilot init you're asked if you want to create a test environment. This test environment contains all the AWS resources to provision a secure network (VPC, subnets, security groups and more) as well as other resources that are meant to be shared between multiple services like an Application Load Balancer or an ECS Cluster. When you deploy your service into your test environment, your service will use the test environment's network and resources. Your application can have multiple environments, and each will have its own networking and shared resources infrastructure. While Copilot creates a test environment for you when you get started, it's common to create a new, seperate environment for production. This production environment will be completly independent from the test environment, with its own networking stack and its own copy of services. By having both a test environment and a production environment, you can deploy changes to your test environment, validate them, then promote them to the production environment. In the diagram below we have an application called MyApp with two services, API and Backend . Those two services are deployed to the two environments, test and prod . You can see that in the test environment, both services are running only one container while the prod services have more containers running. Services can use different configurations depending on the environment they're deployed in. For more check out the using environment variables guide. Creating an Environment To create a new environment in your app, you can run copilot env init from within your workspace. Copilot will ask you what you want to name this environment and what profile you'd like to use to bootstrap the environment. These profiles are AWS named profiles which are associated with a particular account and region. When you select one of these profiles, your environment will be created in whichever account and region that profile is associated with. $ copilot env init After you run copilot env init you can watch as Copilot sets up all the environment resources, which can take a few minutes. Once all those resources are created, the environment will be linked back to the application account. This allows actors in the application account to manage the environment even without access to the environment account. This linking process also creates and configures new regional ECR repositories, if necessary. Deploying a Service When you first create a new environment, no services are deployed to it. To deploy a service run copilot deploy from that service's directory, and you'll be prompted to select which environment to deploy to. Environment Infrastructure VPC and Networking Each environment gets its own multi-AZ VPC. Your VPC is the network boundary of your environment, allowing the traffic you expect in and out, and blocking the rest. The VPCs Copilot creates are spread across two availability zones to help balance availability and cost - with each AZ getting a public and private subnet. Your services are launched in the public subnets but can only be reached through your load balancer. Load Balancers and DNS If you set up any service using one of the Load Balanced Service types, Copilot will set up an Application Load Balancer. All Load Balanced Web Services within an environment will share a load balancer by creating app specific listeners on it. Your load balancer is whitelisted to communicate with services in your VPC. Optionally, when you set up an application, you can provide a domain name that you own and is registered in Route 53. If you provide Copilot with a domain name, each time you spin up an environment, we'll create a subdomain environment-name.app-name.your-domain.com, provision an ACM cert, and bind it to your Application Load Balancer so it can use HTTPS. Customize your Environment Optionally, you can customize your environment interactively or using flags to import your existing resources or configure the default environment resources. Currently, only VPC resources are supported to be customized. However, if you want to customize more types of resources, feel free to bring your use cases and cut an issue! Digging into your Environment Now that we've spun up an environment, we can check on it using Copilot. Below are a few common ways to check in on your environment. What environments are part of my app? To see all the environments in your application you can run copilot env ls . $ copilot env ls test production What's in your environment? Running copilot env show will show you a summary of your environment. Here's an example of the output you might see for our test environment. This output includes the the account and region the environment is in, the services deployed to that environment and the tag that all resources created in this environment will have. You can also provide an optional --resources flag to see all AWS resources associated with this environment. $ copilot env show --name test About Name test Production false Region us-west-2 Account ID 693652174720 Services Name Type ---- ---- api Load Balanced Web Service backend Backend Service Tags Key Value --- ----- copilot-application my-app copilot-environment test","title":"Environments"},{"location":"docs/concepts/environments/#creating-an-environment","text":"To create a new environment in your app, you can run copilot env init from within your workspace. Copilot will ask you what you want to name this environment and what profile you'd like to use to bootstrap the environment. These profiles are AWS named profiles which are associated with a particular account and region. When you select one of these profiles, your environment will be created in whichever account and region that profile is associated with. $ copilot env init After you run copilot env init you can watch as Copilot sets up all the environment resources, which can take a few minutes. Once all those resources are created, the environment will be linked back to the application account. This allows actors in the application account to manage the environment even without access to the environment account. This linking process also creates and configures new regional ECR repositories, if necessary.","title":"Creating an Environment"},{"location":"docs/concepts/environments/#deploying-a-service","text":"When you first create a new environment, no services are deployed to it. To deploy a service run copilot deploy from that service's directory, and you'll be prompted to select which environment to deploy to.","title":"Deploying a Service"},{"location":"docs/concepts/environments/#environment-infrastructure","text":"","title":"Environment Infrastructure"},{"location":"docs/concepts/environments/#vpc-and-networking","text":"Each environment gets its own multi-AZ VPC. Your VPC is the network boundary of your environment, allowing the traffic you expect in and out, and blocking the rest. The VPCs Copilot creates are spread across two availability zones to help balance availability and cost - with each AZ getting a public and private subnet. Your services are launched in the public subnets but can only be reached through your load balancer.","title":"VPC and Networking"},{"location":"docs/concepts/environments/#load-balancers-and-dns","text":"If you set up any service using one of the Load Balanced Service types, Copilot will set up an Application Load Balancer. All Load Balanced Web Services within an environment will share a load balancer by creating app specific listeners on it. Your load balancer is whitelisted to communicate with services in your VPC. Optionally, when you set up an application, you can provide a domain name that you own and is registered in Route 53. If you provide Copilot with a domain name, each time you spin up an environment, we'll create a subdomain environment-name.app-name.your-domain.com, provision an ACM cert, and bind it to your Application Load Balancer so it can use HTTPS.","title":"Load Balancers and DNS"},{"location":"docs/concepts/environments/#customize-your-environment","text":"Optionally, you can customize your environment interactively or using flags to import your existing resources or configure the default environment resources. Currently, only VPC resources are supported to be customized. However, if you want to customize more types of resources, feel free to bring your use cases and cut an issue!","title":"Customize your Environment"},{"location":"docs/concepts/environments/#digging-into-your-environment","text":"Now that we've spun up an environment, we can check on it using Copilot. Below are a few common ways to check in on your environment.","title":"Digging into your Environment"},{"location":"docs/concepts/environments/#what-environments-are-part-of-my-app","text":"To see all the environments in your application you can run copilot env ls . $ copilot env ls test production","title":"What environments are part of my app?"},{"location":"docs/concepts/environments/#whats-in-your-environment","text":"Running copilot env show will show you a summary of your environment. Here's an example of the output you might see for our test environment. This output includes the the account and region the environment is in, the services deployed to that environment and the tag that all resources created in this environment will have. You can also provide an optional --resources flag to see all AWS resources associated with this environment. $ copilot env show --name test About Name test Production false Region us-west-2 Account ID 693652174720 Services Name Type ---- ---- api Load Balanced Web Service backend Backend Service Tags Key Value --- ----- copilot-application my-app copilot-environment test","title":"What's in your environment?"},{"location":"docs/concepts/overview/","text":"Concepts Copilot makes it super easy to set up and deploy your containers on AWS - but getting started is only the first step of the journey. What happens when you want to have one copy of your service running only for testing and another copy serving production traffic? What happens when you want to add another service? How do you manage deploying to all of these services? Copilot wants to help you with all of these things so let's jump into some of Copilot's core concepts to understand how they can help. Services A service is your code and all of the supporting infrastructure needed to get it up and running on AWS. When you first get started setting up a service, Copilot will ask you what type of service you want to create. The type of service determines the infrastructure that'll be created to support your code. If you want your code to serve traffic from the internet, for example, Copilot can set up an Application Load Balancer and an Amazon ECS Service running on AWS Fargate. Once you've told Copilot what type of service you're building, Copilot will take care of building your code's Dockerfile and storing the images securely in an Amazon ECR repository. Copilot will also create a simple file called the manifest which contains all the knobs and toggles for your service. This includes things like how much memory and CPU should be allocated to each copy of your service, how many copies of your service you want running, and more. Environments Rumor has it, there are people out there that can write perfect code on the first go without any bugs. While we tip our hats to those folks, we believe it's important to be able to test new code on a non-customer facing version of your service before promoting to production. In Copilot we do this by using environments . Each environment can have its own version of a service running allowing you to create a \"test\" and \"production\" environment. You can deploy your service to the test environment, make sure everything looks good, then deploy to your production environment. Since each environment is independent, if you deploy a bug to your test environment, customers using a service deployed to your production environment will be fine. Until now we've been talking about just one service, but what happens when you want to add another service? Perhaps you want to add a backend service to complement your frontend service. Each environment contains a set of resources shared between all the deployed services - these resources include the network (VPC, Subnets, Security Groups, etc...), the ECS Cluster, and the load balancer. If you deploy both your frontend and backend service to your test environment, both services will share the same network and cluster. Applications An Application is a collection of services and environments. When you get started with Copilot, the first thing you'll be asked to do is choose an application name. This can be a high level description of the product you're trying to build. An example might be an application named \"chat\" which has two services \"frontend\" and \"api\" . These two services could then be deployed to a \"test\" and \"production\" environment. Pipelines Now that you've got an application with a few services deployed to a couple of environments, staying on top of those deployments can become tricky. Copilot can help by setting up a release pipeline that deploys your service whenever you push to your git repositry. When a push is detected, your pipeline will build your service, push the image to ECR, and deploy to your environments. A common pattern is to set up a pipeline for a particular service that deploys to a test environment, runs automated testing, then deploys to the production environment.","title":"Overview"},{"location":"docs/concepts/overview/#concepts","text":"Copilot makes it super easy to set up and deploy your containers on AWS - but getting started is only the first step of the journey. What happens when you want to have one copy of your service running only for testing and another copy serving production traffic? What happens when you want to add another service? How do you manage deploying to all of these services? Copilot wants to help you with all of these things so let's jump into some of Copilot's core concepts to understand how they can help.","title":"Concepts"},{"location":"docs/concepts/overview/#services","text":"A service is your code and all of the supporting infrastructure needed to get it up and running on AWS. When you first get started setting up a service, Copilot will ask you what type of service you want to create. The type of service determines the infrastructure that'll be created to support your code. If you want your code to serve traffic from the internet, for example, Copilot can set up an Application Load Balancer and an Amazon ECS Service running on AWS Fargate. Once you've told Copilot what type of service you're building, Copilot will take care of building your code's Dockerfile and storing the images securely in an Amazon ECR repository. Copilot will also create a simple file called the manifest which contains all the knobs and toggles for your service. This includes things like how much memory and CPU should be allocated to each copy of your service, how many copies of your service you want running, and more.","title":"Services"},{"location":"docs/concepts/overview/#environments","text":"Rumor has it, there are people out there that can write perfect code on the first go without any bugs. While we tip our hats to those folks, we believe it's important to be able to test new code on a non-customer facing version of your service before promoting to production. In Copilot we do this by using environments . Each environment can have its own version of a service running allowing you to create a \"test\" and \"production\" environment. You can deploy your service to the test environment, make sure everything looks good, then deploy to your production environment. Since each environment is independent, if you deploy a bug to your test environment, customers using a service deployed to your production environment will be fine. Until now we've been talking about just one service, but what happens when you want to add another service? Perhaps you want to add a backend service to complement your frontend service. Each environment contains a set of resources shared between all the deployed services - these resources include the network (VPC, Subnets, Security Groups, etc...), the ECS Cluster, and the load balancer. If you deploy both your frontend and backend service to your test environment, both services will share the same network and cluster.","title":"Environments"},{"location":"docs/concepts/overview/#applications","text":"An Application is a collection of services and environments. When you get started with Copilot, the first thing you'll be asked to do is choose an application name. This can be a high level description of the product you're trying to build. An example might be an application named \"chat\" which has two services \"frontend\" and \"api\" . These two services could then be deployed to a \"test\" and \"production\" environment.","title":"Applications"},{"location":"docs/concepts/overview/#pipelines","text":"Now that you've got an application with a few services deployed to a couple of environments, staying on top of those deployments can become tricky. Copilot can help by setting up a release pipeline that deploys your service whenever you push to your git repositry. When a push is detected, your pipeline will build your service, push the image to ECR, and deploy to your environments. A common pattern is to set up a pipeline for a particular service that deploys to a test environment, runs automated testing, then deploys to the production environment.","title":"Pipelines"},{"location":"docs/concepts/pipelines/","text":"Having an automated release process is one of the most important parts of software delivery so Copilot wants to make setting up that automated release process as easy as possible \ud83d\ude80. In this section, we'll talk about using Copilot to set up a CodePipeline which automatically builds your service code when you push to GitHub, deploys to your environments, and runs automated testing. Why? I won't get too philosophical about releasing software, but what's the point of having a release pipeline? With copilot deploy you can deploy your service directly from your computer to ECS, why add a middleman? That's a great question. For some apps, manually using deploy is enough, but as your release process gets more complicated (as you add more environments or add automated testing for example) you want to offload the boring work of repeatably orchestrating that process to a service. Having two services, each having two environments (test and production, say) and wanting to run integration tests after you deploy to your test environment becomes surprisingly cumbersome to do by hand. Using an automated release tool like CodePipeline helps make your release manageable. Even if your release isn't particularly complicated, knowing that you can just git push to deploy your change always feels a little magical \ud83c\udf08. Pipeline structure Copilot can set up a CodePipeline for you with a few commands - but before we jump into that, let's talk a little bit about the structure of the pipeline we'll be generating. Our pipeline will have the following basic structure: GitHub Source - when you push to a configured branch (master by default), a new pipeline execution is triggered. Build Stage - after your code is pulled from GitHub, your service's container image is built and published to every environment's ECR repository. Deploy Stages - after your code is built, you can deploy to any and all of your environments, with optional post deployment tests or manual approvals. Once you've set up a CodePipeline using Copilot, all you'll have to do is push to your GitHub repository, and CodePipeline will orchestrate the deployments. Want to learn more about CodePipeline? Check out their getting started docs . Creating a Pipeline in 3 steps Creating a Pipeline only requires three steps: Preparing the pipeline structure. Committing the generated buildspec.yml . Creating the actual CodePipeline. Follow the three steps below, from your workspace root: $ copilot pipeline init $ git add copilot/buildspec.yml && git commit -m \"Adding Pipeline Buildspec\" && git push $ copilot pipeline update \u2728 And you'll have a new pipeline configured in your application account. Want to understand a little bit more what's going on? Read on! Setting up a Pipeline, step by step Step 1: Configuring your Pipeline Pipeline configurations are created at a workspace level. If your workspace has a single service then your pipeline will be triggered only for that service. However, if you have multiple services in a workspace then it will build all the services in the workspace. To start setting up a pipeline, cd into your service(s)'s workspace and run: $ copilot pipeline init This won't create your pipeline, but it will create some local files that will be used when creating your pipeline. Release order : You'll be prompted for environments you want to deploy to - select them based on the order you want them to be deployed in your pipeline (deployments happen one environment at a time). You may, for example, want to deploy to your test environment first, and then your prod environment. Tracking repository : After you've selected the environments you want to deploy to, you'll be prompted to select which GitHub repository you want your CodePipeline to track. This is the repository that, when pushed to, will trigger a Pipeline execution (if the repository you're interested in doesn't show up, you can pass it in using the --github-url flag). Personal access token : In order to allow CodePipeline to track your GitHub repository, you'll need to provide a GitHub Personal Access Token. You can read how to do that here . Your token needs to have repo and admin:repo_hook permissions (so CodePipeline can create a WebHook on your behalf). Your GitHub Personal Access Token is stored securely in AWS Secrets Manager . Step 2: Updating the Pipeline manifest (optional) Just like your service has a simple manifest file, so does your pipeline. After you run pipeline init , two files are created, the pipeline.yml and buildspec.yml , both created in your copilot/ directory. If you poke in, you'll see a file that looks something like this (for a service called \"api-frontend\" with two environments, \"test\" and \"prod\"): # This YAML file defines the relationship and deployment ordering of your environments. # The name of the pipeline name : pipeline-ecs-kudos-kohidave-demo-api-frontend # The version of the schema used in this template version : 1 # This section defines the source artifacts. source : # The name of the provider that is used to store the source artifacts. provider : GitHub # Additional properties that further specifies the exact location # the artifacts should be sourced from. For example, the GitHub provider # has the following properties: repository, branch. properties : access_token_secret : github-token-ecs-kudos-demo-api-frontend branch : master repository : https://github.com/kohidave/demo-api-frontend # The deployment section defines the order the pipeline will deploy # to your environments. stages : - # The name of the environment to deploy to. name : test test_commands : - make test - echo \"woo! Tests passed\" - # The name of the environment to deploy to. name : prod # requires_approval: true There are 3 main parts of this file, the name field, which is the name of your CodePipeline, the source section, which details the GitHub repository and branch to track, and the stages section, which lists the environments you want this pipeline to deploy to. You can update this any time, but you must run copilot pipeline update afterwards. Typically, you'll update this file if you add new environments you want to deploy to, or want to track a different branch. Step 3: Updating the Buildspec (optional) Along with the pipeline.yml , the pipeline init command also generated a buildspec.yml file in the copilot/ directory. This contains the instructions for building and publishing your service. If you want to run any additional commands, besides docker build , such as unit tests or style checkers, feel free to add it to the buildspec's build phase. When this buildspec runs, it pulls down the version of Copilot which was used when you ran pipeline init , to ensure backwards compatibility. Step 4: Creating your Pipeline Now that your pipeline.yml and buildspec.yml are created, check them in and push them to your GitHub repository. The buildspec.yml is needed for your Pipeline's build stage to run successfully. Once you've done that, to actually create your pipeline run: copilot pipeline update This parses your pipeline.yml , creates a CodePipeline in the same account and region as your project (though it can deploy cross account and cross region) and kicks off a pipeline execution. Log into the AWS Console to watch your Pipeline go. Adding Tests Of course, one of the most important parts of a Pipeline is the automated testing. To add your own test commands, include the commands you'd like to run after your deploy step in the test_commands section. If all the commands succeed, your change is promoted to the next stage. Adding test_commands generates a CodeBuild project with the aws/codebuild/amazonlinux2-x86_64-standard:3.0 image - so most commands from Amazon Linux 2 (including make ) are available for use. In the example below, the Pipeline will run make test command (in your source code directory) and only promote the change to the prod stage if that command exists successfully. name : pipeline-ecs-kudos-kohidave-demo-api-frontend version : 1 source : provider : GitHub properties : access_token_secret : github-token-ecs-kudos-demo-api-frontend branch : master repository : https://github.com/kohidave/demo-api-frontend stages : - name : test # A change will only deploy to the production stage if the # make test and echo commands exit successfully. test_commands : - make test - echo \"woo! Tests passed\" - name : prod","title":"Pipelines"},{"location":"docs/concepts/pipelines/#why","text":"I won't get too philosophical about releasing software, but what's the point of having a release pipeline? With copilot deploy you can deploy your service directly from your computer to ECS, why add a middleman? That's a great question. For some apps, manually using deploy is enough, but as your release process gets more complicated (as you add more environments or add automated testing for example) you want to offload the boring work of repeatably orchestrating that process to a service. Having two services, each having two environments (test and production, say) and wanting to run integration tests after you deploy to your test environment becomes surprisingly cumbersome to do by hand. Using an automated release tool like CodePipeline helps make your release manageable. Even if your release isn't particularly complicated, knowing that you can just git push to deploy your change always feels a little magical \ud83c\udf08.","title":"Why?"},{"location":"docs/concepts/pipelines/#pipeline-structure","text":"Copilot can set up a CodePipeline for you with a few commands - but before we jump into that, let's talk a little bit about the structure of the pipeline we'll be generating. Our pipeline will have the following basic structure: GitHub Source - when you push to a configured branch (master by default), a new pipeline execution is triggered. Build Stage - after your code is pulled from GitHub, your service's container image is built and published to every environment's ECR repository. Deploy Stages - after your code is built, you can deploy to any and all of your environments, with optional post deployment tests or manual approvals. Once you've set up a CodePipeline using Copilot, all you'll have to do is push to your GitHub repository, and CodePipeline will orchestrate the deployments. Want to learn more about CodePipeline? Check out their getting started docs .","title":"Pipeline structure"},{"location":"docs/concepts/pipelines/#creating-a-pipeline-in-3-steps","text":"Creating a Pipeline only requires three steps: Preparing the pipeline structure. Committing the generated buildspec.yml . Creating the actual CodePipeline. Follow the three steps below, from your workspace root: $ copilot pipeline init $ git add copilot/buildspec.yml && git commit -m \"Adding Pipeline Buildspec\" && git push $ copilot pipeline update \u2728 And you'll have a new pipeline configured in your application account. Want to understand a little bit more what's going on? Read on!","title":"Creating a Pipeline in 3 steps"},{"location":"docs/concepts/pipelines/#setting-up-a-pipeline-step-by-step","text":"","title":"Setting up a Pipeline, step by step"},{"location":"docs/concepts/pipelines/#step-1-configuring-your-pipeline","text":"Pipeline configurations are created at a workspace level. If your workspace has a single service then your pipeline will be triggered only for that service. However, if you have multiple services in a workspace then it will build all the services in the workspace. To start setting up a pipeline, cd into your service(s)'s workspace and run: $ copilot pipeline init This won't create your pipeline, but it will create some local files that will be used when creating your pipeline. Release order : You'll be prompted for environments you want to deploy to - select them based on the order you want them to be deployed in your pipeline (deployments happen one environment at a time). You may, for example, want to deploy to your test environment first, and then your prod environment. Tracking repository : After you've selected the environments you want to deploy to, you'll be prompted to select which GitHub repository you want your CodePipeline to track. This is the repository that, when pushed to, will trigger a Pipeline execution (if the repository you're interested in doesn't show up, you can pass it in using the --github-url flag). Personal access token : In order to allow CodePipeline to track your GitHub repository, you'll need to provide a GitHub Personal Access Token. You can read how to do that here . Your token needs to have repo and admin:repo_hook permissions (so CodePipeline can create a WebHook on your behalf). Your GitHub Personal Access Token is stored securely in AWS Secrets Manager .","title":"Step 1: Configuring your Pipeline"},{"location":"docs/concepts/pipelines/#step-2-updating-the-pipeline-manifest-optional","text":"Just like your service has a simple manifest file, so does your pipeline. After you run pipeline init , two files are created, the pipeline.yml and buildspec.yml , both created in your copilot/ directory. If you poke in, you'll see a file that looks something like this (for a service called \"api-frontend\" with two environments, \"test\" and \"prod\"): # This YAML file defines the relationship and deployment ordering of your environments. # The name of the pipeline name : pipeline-ecs-kudos-kohidave-demo-api-frontend # The version of the schema used in this template version : 1 # This section defines the source artifacts. source : # The name of the provider that is used to store the source artifacts. provider : GitHub # Additional properties that further specifies the exact location # the artifacts should be sourced from. For example, the GitHub provider # has the following properties: repository, branch. properties : access_token_secret : github-token-ecs-kudos-demo-api-frontend branch : master repository : https://github.com/kohidave/demo-api-frontend # The deployment section defines the order the pipeline will deploy # to your environments. stages : - # The name of the environment to deploy to. name : test test_commands : - make test - echo \"woo! Tests passed\" - # The name of the environment to deploy to. name : prod # requires_approval: true There are 3 main parts of this file, the name field, which is the name of your CodePipeline, the source section, which details the GitHub repository and branch to track, and the stages section, which lists the environments you want this pipeline to deploy to. You can update this any time, but you must run copilot pipeline update afterwards. Typically, you'll update this file if you add new environments you want to deploy to, or want to track a different branch.","title":"Step 2: Updating the Pipeline manifest (optional)"},{"location":"docs/concepts/pipelines/#step-3-updating-the-buildspec-optional","text":"Along with the pipeline.yml , the pipeline init command also generated a buildspec.yml file in the copilot/ directory. This contains the instructions for building and publishing your service. If you want to run any additional commands, besides docker build , such as unit tests or style checkers, feel free to add it to the buildspec's build phase. When this buildspec runs, it pulls down the version of Copilot which was used when you ran pipeline init , to ensure backwards compatibility.","title":"Step 3: Updating the Buildspec (optional)"},{"location":"docs/concepts/pipelines/#step-4-creating-your-pipeline","text":"Now that your pipeline.yml and buildspec.yml are created, check them in and push them to your GitHub repository. The buildspec.yml is needed for your Pipeline's build stage to run successfully. Once you've done that, to actually create your pipeline run: copilot pipeline update This parses your pipeline.yml , creates a CodePipeline in the same account and region as your project (though it can deploy cross account and cross region) and kicks off a pipeline execution. Log into the AWS Console to watch your Pipeline go.","title":"Step 4: Creating your Pipeline"},{"location":"docs/concepts/pipelines/#adding-tests","text":"Of course, one of the most important parts of a Pipeline is the automated testing. To add your own test commands, include the commands you'd like to run after your deploy step in the test_commands section. If all the commands succeed, your change is promoted to the next stage. Adding test_commands generates a CodeBuild project with the aws/codebuild/amazonlinux2-x86_64-standard:3.0 image - so most commands from Amazon Linux 2 (including make ) are available for use. In the example below, the Pipeline will run make test command (in your source code directory) and only promote the change to the prod stage if that command exists successfully. name : pipeline-ecs-kudos-kohidave-demo-api-frontend version : 1 source : provider : GitHub properties : access_token_secret : github-token-ecs-kudos-demo-api-frontend branch : master repository : https://github.com/kohidave/demo-api-frontend stages : - name : test # A change will only deploy to the production stage if the # make test and echo commands exit successfully. test_commands : - make test - echo \"woo! Tests passed\" - name : prod","title":"Adding Tests"},{"location":"docs/concepts/services/","text":"One of the awesome things about containers is that once you've written your code, running it locally is as easy as typing docker run . Copilot makes running those same containers on AWS as easy as running copilot init . Copilot will build your image, push it to Amazon ECR and set up all the infrastructure to run your service in a scalable and secure way. Creating a Service Creating a service to run your containers on AWS can be done in a few ways. The easiest way is by running the init command from the same directory as your Dockerfile. $ copilot init You'll be asked which application do you want this service to be a part of (or to create an application if there isn't one). Copilot will then ask about the type of service you're trying to build. After selecting a service type, Copilot will detect any health checks or exposed ports from your Dockerfile and ask if you'd like to deploy. Choosing a Service Type We mentioned before that Copilot will set up all the infrastructure your service needs to run. But how does it know what kind of infrastructure to use? When you're setting up a service, Copilot will ask you about what kind of service you want to build. Load Balanced Web Service Do you want your service to serve internet traffic? You can select a Load Balanced Web Service and Copilot will provision an application load balancer, security groups, an ECS Service and run your service on Fargate. Backend Service If you want a service that can't be accessed externally, but only from other services within your application, you can create a Backend Service . Copilot will provision an ECS Service running on AWS Fargate, but won't set up any internet-facing endpoints. Config and the Manifest After you've run copilot init you might have noticed that Copilot created a file called manifest.yml in the copilot directory. This manifest file contains common configuration options for your service. While the exact set of options depends on the type of service you're running, common ones include the resources allocated to your service (like memory and CPU), health checks, and environment variables. Let's take a look at the manifest for a Load Balanced Web Service called front-end . name : front-end type : Load Balanced Web Service image : # Path to your service's Dockerfile. build : ./Dockerfile # Port exposed through your container to route traffic to it. port : 8080 http : # Requests to this path will be forwarded to your service. # To match all requests you can use the \"/\" path. path : '/' # You can specify a custom health check path. The default is \"/\" # healthcheck: '/' # Number of CPU units for the task. cpu : 256 # Amount of memory in MiB used by the task. memory : 512 # Number of tasks that should be running in your service. count : 1 # Optional fields for more advanced use-cases. # variables : # Pass environment variables as key value pairs. LOG_LEVEL : info #secrets: # Pass secrets from AWS Systems Manager (SSM) Parameter Store. # GITHUB_TOKEN: GH_SECRET_TOKEN # The key is the name of the environment variable, # the value is the name of the SSM parameter. # You can override any of the values defined above by environment. environments : prod : count : 2 # Number of tasks to run for the \"test\" environment. To learn about the specification of manifest files, see the manifests page. Deploying a Service Once you've set up your service, you can deploy it (and any changes to your manifest) by running the deploy command: $ copilot deploy Running this command will: Build your image locally Push to your service's ECR repository Convert your manifest file to CloudFormation Package any additional infrastructure into CloudFormation Deploy your updated service and resources to CloudFormation If you have multiple environments, you'll be prompted to select which environment you want to deploy to. Digging into your Service Now that we've got a service up and running, we can check on it using Copilot. Below are a few common ways to check in on your deployed service. What's in your service? Running copilot svc show will show you a summary of your service. Here's an example of the output you might see for a load balanced web application. This output includes the configuration of your service for each environment, all the endpoints for your service, and the environment variables passed into your service. You can also provide an optional --resources flag to see all AWS resources associated with your service. $ copilot svc show About Application my-app Name front-end Type Load Balanced Web Service Configurations Environment Tasks CPU ( vCPU ) Memory ( MiB ) Port test 1 0 .25 512 80 Routes Environment URL test http://my-ap-Publi-1RV8QEBNTEQCW-1762184596.ca-central-1.elb.amazonaws.com Service Discovery Environment Namespace test front-end.my-app.local:8080 Variables Name Environment Value COPILOT_APPLICATION_NAME test my-app COPILOT_ENVIRONMENT_NAME test test COPILOT_LB_DNS test my-ap-Publi-1RV8QEBNTEQCW-1762184596.ca-central-1.elb.amazonaws.com COPILOT_SERVICE_DISCOVERY_ENDPOINT test my-app.local COPILOT_SERVICE_NAME test front-end What's your service status? Often it's handy to be able to check on the status of your service. Are all the instances of my service healthy? Are there any alarms firing? To do that, you can run copilot svc status to get a summary of your service's status. $ copilot svc status Service Status ACTIVE 1 / 1 running tasks ( 0 pending ) Last Deployment Updated At 12 minutes ago Task Definition arn:aws:ecs:ca-central-1:693652174720:task-definition/my-app-test-front-end:1 Task Status ID Image Digest Last Status Health Status Started At Stopped At 37236ed3 da3cfcdd RUNNING HEALTHY 12 minutes ago - Alarms Name Health Last Updated Reason CPU-Utilization OK 5 minutes ago - Where are my service logs? Checking the your service logs is easy as well. Running copilot svc logs will show the most recent logs of your service. You can follow your logs live with the --follow flag. $ copilot svc logs 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok!","title":"Services"},{"location":"docs/concepts/services/#creating-a-service","text":"Creating a service to run your containers on AWS can be done in a few ways. The easiest way is by running the init command from the same directory as your Dockerfile. $ copilot init You'll be asked which application do you want this service to be a part of (or to create an application if there isn't one). Copilot will then ask about the type of service you're trying to build. After selecting a service type, Copilot will detect any health checks or exposed ports from your Dockerfile and ask if you'd like to deploy.","title":"Creating a Service"},{"location":"docs/concepts/services/#choosing-a-service-type","text":"We mentioned before that Copilot will set up all the infrastructure your service needs to run. But how does it know what kind of infrastructure to use? When you're setting up a service, Copilot will ask you about what kind of service you want to build.","title":"Choosing a Service Type"},{"location":"docs/concepts/services/#load-balanced-web-service","text":"Do you want your service to serve internet traffic? You can select a Load Balanced Web Service and Copilot will provision an application load balancer, security groups, an ECS Service and run your service on Fargate.","title":"Load Balanced Web Service"},{"location":"docs/concepts/services/#backend-service","text":"If you want a service that can't be accessed externally, but only from other services within your application, you can create a Backend Service . Copilot will provision an ECS Service running on AWS Fargate, but won't set up any internet-facing endpoints.","title":"Backend Service"},{"location":"docs/concepts/services/#config-and-the-manifest","text":"After you've run copilot init you might have noticed that Copilot created a file called manifest.yml in the copilot directory. This manifest file contains common configuration options for your service. While the exact set of options depends on the type of service you're running, common ones include the resources allocated to your service (like memory and CPU), health checks, and environment variables. Let's take a look at the manifest for a Load Balanced Web Service called front-end . name : front-end type : Load Balanced Web Service image : # Path to your service's Dockerfile. build : ./Dockerfile # Port exposed through your container to route traffic to it. port : 8080 http : # Requests to this path will be forwarded to your service. # To match all requests you can use the \"/\" path. path : '/' # You can specify a custom health check path. The default is \"/\" # healthcheck: '/' # Number of CPU units for the task. cpu : 256 # Amount of memory in MiB used by the task. memory : 512 # Number of tasks that should be running in your service. count : 1 # Optional fields for more advanced use-cases. # variables : # Pass environment variables as key value pairs. LOG_LEVEL : info #secrets: # Pass secrets from AWS Systems Manager (SSM) Parameter Store. # GITHUB_TOKEN: GH_SECRET_TOKEN # The key is the name of the environment variable, # the value is the name of the SSM parameter. # You can override any of the values defined above by environment. environments : prod : count : 2 # Number of tasks to run for the \"test\" environment. To learn about the specification of manifest files, see the manifests page.","title":"Config and the Manifest"},{"location":"docs/concepts/services/#deploying-a-service","text":"Once you've set up your service, you can deploy it (and any changes to your manifest) by running the deploy command: $ copilot deploy Running this command will: Build your image locally Push to your service's ECR repository Convert your manifest file to CloudFormation Package any additional infrastructure into CloudFormation Deploy your updated service and resources to CloudFormation If you have multiple environments, you'll be prompted to select which environment you want to deploy to.","title":"Deploying a Service"},{"location":"docs/concepts/services/#digging-into-your-service","text":"Now that we've got a service up and running, we can check on it using Copilot. Below are a few common ways to check in on your deployed service.","title":"Digging into your Service"},{"location":"docs/concepts/services/#whats-in-your-service","text":"Running copilot svc show will show you a summary of your service. Here's an example of the output you might see for a load balanced web application. This output includes the configuration of your service for each environment, all the endpoints for your service, and the environment variables passed into your service. You can also provide an optional --resources flag to see all AWS resources associated with your service. $ copilot svc show About Application my-app Name front-end Type Load Balanced Web Service Configurations Environment Tasks CPU ( vCPU ) Memory ( MiB ) Port test 1 0 .25 512 80 Routes Environment URL test http://my-ap-Publi-1RV8QEBNTEQCW-1762184596.ca-central-1.elb.amazonaws.com Service Discovery Environment Namespace test front-end.my-app.local:8080 Variables Name Environment Value COPILOT_APPLICATION_NAME test my-app COPILOT_ENVIRONMENT_NAME test test COPILOT_LB_DNS test my-ap-Publi-1RV8QEBNTEQCW-1762184596.ca-central-1.elb.amazonaws.com COPILOT_SERVICE_DISCOVERY_ENDPOINT test my-app.local COPILOT_SERVICE_NAME test front-end","title":"What's in your service?"},{"location":"docs/concepts/services/#whats-your-service-status","text":"Often it's handy to be able to check on the status of your service. Are all the instances of my service healthy? Are there any alarms firing? To do that, you can run copilot svc status to get a summary of your service's status. $ copilot svc status Service Status ACTIVE 1 / 1 running tasks ( 0 pending ) Last Deployment Updated At 12 minutes ago Task Definition arn:aws:ecs:ca-central-1:693652174720:task-definition/my-app-test-front-end:1 Task Status ID Image Digest Last Status Health Status Started At Stopped At 37236ed3 da3cfcdd RUNNING HEALTHY 12 minutes ago - Alarms Name Health Last Updated Reason CPU-Utilization OK 5 minutes ago -","title":"What's your service status?"},{"location":"docs/concepts/services/#where-are-my-service-logs","text":"Checking the your service logs is easy as well. Running copilot svc logs will show the most recent logs of your service. You can follow your logs live with the --follow flag. $ copilot svc logs 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok! 37236ed 10 .0.0.30 \ud83d\ude91 Health-check ok!","title":"Where are my service logs?"},{"location":"docs/developing/additional-aws-resources/","text":"Additional AWS Resources Additional AWS resources, referred as \"addons\" in the CLI, are any additional AWS services that a service manifest does not integrate by default. For example, an addon can be a DynamoDB table or S3 bucket that your service needs to read or write to. How do I add an S3 bucket or DDB Table? Copilot provides the following commands to help you create certain kinds of addons: storage init will create a DynamoDB table or S3 bucket. You can run copilot storage init from your workspace and be guided through some questions to help you set up these resources. How to do I add other resources? For other types of addons, you can add your own custom CloudFormation templates according to the following instructions. Let's say you have a service named webhook in your workspace: . \u2514\u2500\u2500 copilot \u2514\u2500\u2500 webhook \u2514\u2500\u2500 manifest.yml And you want to add a custom DynamoDB table to webhook . Then under the webhook/ directory, create a new addons/ directory and add a CloudFormation template for your instance. . \u2514\u2500\u2500 copilot \u2514\u2500\u2500 webhook \u251c\u2500\u2500 addons \u2502 \u2514\u2500\u2500 mytable-ddb.yaml \u2514\u2500\u2500 manifest.yaml Typically each file under the addons/ directory represents a separate addon and is represented as an AWS CloudFormation (CFN) template . For example, if we want to also add an S3 bucket addon to our service then we could either run storage init or create our own custom, separate mybucket-s3.yaml file. When your service gets deployed, Copilot merges all these files into a single AWS CloudFormation template and creates a nested stack under your service's stack. What does an addon template look like? An addon template can be any valid CloudFormation template. However, Copilot will pass by default the App , Env and Name Parameters for you to customize your resource properties with Conditions or Mappings if you wish to. If you need to access your Resources from your ECS task, make sure to: Define an IAM ManagedPolicy resource in your template that holds the permissions for your task and add an Output so that the permission is injected to your ECS Task Role. Create an Output for any value that you want to be injected as an environment variable to your ECS tasks. Here is an example template layout for a DynamoDB table addon: # You can use any of these parameters to create conditions or mappings in your template. Parameters : App : Type : String Description : Your application's name. Env : Type : String Description : The environment name your service, job, or workflow is being deployed to. Name : Type : String Description : The name of the service, job, or workflow being deployed. Resources : # Create your resource here, such as an AWS::DynamoDB::Table: # MyTable: # Type: AWS::DynamoDB::Table # Properties: # ... # 1. In addition to your resource, if you need to access the resource from your ECS task # then you need to create an AWS::IAM::ManagedPolicy that holds the permissions for your resource. # # For example, below is a sample policy for MyTable: MyTableAccessPolicy : Type : AWS::IAM::ManagedPolicy Properties : PolicyDocument : Version : 2012-10-17 Statement : - Sid : DDBActions Effect : Allow Action : - dynamodb:BatchGet* - dynamodb:DescribeStream - dynamodb:DescribeTable - dynamodb:Get* - dynamodb:Query - dynamodb:Scan - dynamodb:BatchWrite* - dynamodb:Create* - dynamodb:Delete* - dynamodb:Update* - dynamodb:PutItem Resource : !Sub ${ MyTable.Arn} Outputs : # 2. If you want to inject a property of your resource as an environment variable to your ECS task, # then you need to define an output for it. # # For example, the output MyTableName will be injected in capital snake case, MY_TABLE_NAME, to your task. MyTableName : Description : \"The name of this DynamoDB.\" Value : !Ref MyTable # 1. You also need to output the IAM ManagedPolicy so that Copilot can inject it to your ECS task role. MyTableAccessPolicyArn : Description : \"The ARN of the ManagedPolicy to attach to the task role.\" Value : !Ref MyTableAccessPolicy Copilot will include this template as a nested stack under your service on your next release! Info We recommend following Amazon IAM best practices while defining AWS Managed Policies for the additional resources, including: Grant least privilege to the policies defined in your addons/ directory. Use policy conditions for extra security to restrict your policies to access only the resources defined in your addons/ directory.","title":"Additional AWS Resources"},{"location":"docs/developing/additional-aws-resources/#additional-aws-resources","text":"Additional AWS resources, referred as \"addons\" in the CLI, are any additional AWS services that a service manifest does not integrate by default. For example, an addon can be a DynamoDB table or S3 bucket that your service needs to read or write to.","title":"Additional AWS Resources"},{"location":"docs/developing/additional-aws-resources/#how-do-i-add-an-s3-bucket-or-ddb-table","text":"Copilot provides the following commands to help you create certain kinds of addons: storage init will create a DynamoDB table or S3 bucket. You can run copilot storage init from your workspace and be guided through some questions to help you set up these resources.","title":"How do I add an S3 bucket or DDB Table?"},{"location":"docs/developing/additional-aws-resources/#how-to-do-i-add-other-resources","text":"For other types of addons, you can add your own custom CloudFormation templates according to the following instructions. Let's say you have a service named webhook in your workspace: . \u2514\u2500\u2500 copilot \u2514\u2500\u2500 webhook \u2514\u2500\u2500 manifest.yml And you want to add a custom DynamoDB table to webhook . Then under the webhook/ directory, create a new addons/ directory and add a CloudFormation template for your instance. . \u2514\u2500\u2500 copilot \u2514\u2500\u2500 webhook \u251c\u2500\u2500 addons \u2502 \u2514\u2500\u2500 mytable-ddb.yaml \u2514\u2500\u2500 manifest.yaml Typically each file under the addons/ directory represents a separate addon and is represented as an AWS CloudFormation (CFN) template . For example, if we want to also add an S3 bucket addon to our service then we could either run storage init or create our own custom, separate mybucket-s3.yaml file. When your service gets deployed, Copilot merges all these files into a single AWS CloudFormation template and creates a nested stack under your service's stack.","title":"How to do I add other resources?"},{"location":"docs/developing/additional-aws-resources/#what-does-an-addon-template-look-like","text":"An addon template can be any valid CloudFormation template. However, Copilot will pass by default the App , Env and Name Parameters for you to customize your resource properties with Conditions or Mappings if you wish to. If you need to access your Resources from your ECS task, make sure to: Define an IAM ManagedPolicy resource in your template that holds the permissions for your task and add an Output so that the permission is injected to your ECS Task Role. Create an Output for any value that you want to be injected as an environment variable to your ECS tasks. Here is an example template layout for a DynamoDB table addon: # You can use any of these parameters to create conditions or mappings in your template. Parameters : App : Type : String Description : Your application's name. Env : Type : String Description : The environment name your service, job, or workflow is being deployed to. Name : Type : String Description : The name of the service, job, or workflow being deployed. Resources : # Create your resource here, such as an AWS::DynamoDB::Table: # MyTable: # Type: AWS::DynamoDB::Table # Properties: # ... # 1. In addition to your resource, if you need to access the resource from your ECS task # then you need to create an AWS::IAM::ManagedPolicy that holds the permissions for your resource. # # For example, below is a sample policy for MyTable: MyTableAccessPolicy : Type : AWS::IAM::ManagedPolicy Properties : PolicyDocument : Version : 2012-10-17 Statement : - Sid : DDBActions Effect : Allow Action : - dynamodb:BatchGet* - dynamodb:DescribeStream - dynamodb:DescribeTable - dynamodb:Get* - dynamodb:Query - dynamodb:Scan - dynamodb:BatchWrite* - dynamodb:Create* - dynamodb:Delete* - dynamodb:Update* - dynamodb:PutItem Resource : !Sub ${ MyTable.Arn} Outputs : # 2. If you want to inject a property of your resource as an environment variable to your ECS task, # then you need to define an output for it. # # For example, the output MyTableName will be injected in capital snake case, MY_TABLE_NAME, to your task. MyTableName : Description : \"The name of this DynamoDB.\" Value : !Ref MyTable # 1. You also need to output the IAM ManagedPolicy so that Copilot can inject it to your ECS task role. MyTableAccessPolicyArn : Description : \"The ARN of the ManagedPolicy to attach to the task role.\" Value : !Ref MyTableAccessPolicy Copilot will include this template as a nested stack under your service on your next release! Info We recommend following Amazon IAM best practices while defining AWS Managed Policies for the additional resources, including: Grant least privilege to the policies defined in your addons/ directory. Use policy conditions for extra security to restrict your policies to access only the resources defined in your addons/ directory.","title":"What does an addon template look like?"},{"location":"docs/developing/environment-variables/","text":"Environment Variables Environment variables are variables that are available to your service, based on the environment they're running in. Your service can reference them without having to define them. Environment variables are useful for when you want to pass in data to your service that's specific to a particular environment. For example, your test database name versus your production database name. Accessing environment variables is usually simply based on the language you're using. Here are some examples of getting an environment variable called DATABASE_NAME in a few different languages. Go dbName := os . Getenv ( \"DATABASE_NAME\" ) Javascript var dbName = process . env . DATABASE_NAME ; Python database_name = os . getenv ( 'DATABASE_NAME' ) What are the Default Environment Variables? By default, the AWS Copilot CLI passes in some default environment variables for your service to use. COPILOT_APPLICATION_NAME - this is the name of the application this service is running in. COPILOT_ENVIRONMENT_NAME - this is the name of the environment the service is running in (test vs prod, for example) COPILOT_SERVICE_NAME - this is the name of the current service. COPILOT_LB_DNS - this is the DNS name of the Load Balancer (if it exists) such as kudos-Publi-MC2WNHAIOAVS-588300247.us-west-2.elb.amazonaws.com . One note, if you're using a custom domain name, this value will still be the Load Balancer's DNS name. COPILOT_SERVICE_DISCOVERY_ENDPOINT - this is the endpoint to add after a service name to talk to another service in your environment via service discovery. The value is {app name}.local . For more information about service discovery checkout our service discovery guide . How do I add my own Environment Variables? Adding your own environment variable is easy. You can add them directly to your manifest in the variables section. The following snippet will pass a environment variable called LOG_LEVEL to your service, with the value set to debug . # in copilot/{service name}/manifest.yml variables : LOG_LEVEL : debug You can also pass in a specific value for an environment variable based on the environment. We'll follow the same example as above, by setting the log level, but overwriting the value to be info in our production environment. Changes to your manifest take effect when you deploy them, so changing them locally is safe. # in copilot/{service name}/manifest.yml variables : LOG_LEVEL : debug environments : production : variables : LOG_LEVEL : info Here's a quick guide showing you how to add environment variables to your app by editing the manifest \ud83d\udc47 How do I know the name of my DynamoDB table, S3 bucket, RDS database, etc? When using the Copilot CLI to provision additional AWS resources, such as DynamoDB tables, S3 buckets, Databases, etc, any output values will be passed in as environment variables to your app. For more information, check out the additional resources guide .","title":"Environment Variables"},{"location":"docs/developing/environment-variables/#environment-variables","text":"Environment variables are variables that are available to your service, based on the environment they're running in. Your service can reference them without having to define them. Environment variables are useful for when you want to pass in data to your service that's specific to a particular environment. For example, your test database name versus your production database name. Accessing environment variables is usually simply based on the language you're using. Here are some examples of getting an environment variable called DATABASE_NAME in a few different languages. Go dbName := os . Getenv ( \"DATABASE_NAME\" ) Javascript var dbName = process . env . DATABASE_NAME ; Python database_name = os . getenv ( 'DATABASE_NAME' )","title":"Environment Variables"},{"location":"docs/developing/environment-variables/#what-are-the-default-environment-variables","text":"By default, the AWS Copilot CLI passes in some default environment variables for your service to use. COPILOT_APPLICATION_NAME - this is the name of the application this service is running in. COPILOT_ENVIRONMENT_NAME - this is the name of the environment the service is running in (test vs prod, for example) COPILOT_SERVICE_NAME - this is the name of the current service. COPILOT_LB_DNS - this is the DNS name of the Load Balancer (if it exists) such as kudos-Publi-MC2WNHAIOAVS-588300247.us-west-2.elb.amazonaws.com . One note, if you're using a custom domain name, this value will still be the Load Balancer's DNS name. COPILOT_SERVICE_DISCOVERY_ENDPOINT - this is the endpoint to add after a service name to talk to another service in your environment via service discovery. The value is {app name}.local . For more information about service discovery checkout our service discovery guide .","title":"What are the Default Environment Variables?"},{"location":"docs/developing/environment-variables/#how-do-i-add-my-own-environment-variables","text":"Adding your own environment variable is easy. You can add them directly to your manifest in the variables section. The following snippet will pass a environment variable called LOG_LEVEL to your service, with the value set to debug . # in copilot/{service name}/manifest.yml variables : LOG_LEVEL : debug You can also pass in a specific value for an environment variable based on the environment. We'll follow the same example as above, by setting the log level, but overwriting the value to be info in our production environment. Changes to your manifest take effect when you deploy them, so changing them locally is safe. # in copilot/{service name}/manifest.yml variables : LOG_LEVEL : debug environments : production : variables : LOG_LEVEL : info Here's a quick guide showing you how to add environment variables to your app by editing the manifest \ud83d\udc47","title":"How do I add my own Environment Variables?"},{"location":"docs/developing/environment-variables/#how-do-i-know-the-name-of-my-dynamodb-table-s3-bucket-rds-database-etc","text":"When using the Copilot CLI to provision additional AWS resources, such as DynamoDB tables, S3 buckets, Databases, etc, any output values will be passed in as environment variables to your app. For more information, check out the additional resources guide .","title":"How do I know the name of my DynamoDB table, S3 bucket, RDS database, etc?"},{"location":"docs/developing/secrets/","text":"Secrets Secrets are sensitive bits of information like OAuth tokens, secret keys or API keys - information that you need in your application code, but shouldn't commit to your source code. In the AWS Copilot CLI secrets are passed in as environment variables (read more about developing with environment variables ) but they're treated differently, due to their sensitive nature. How do I add Secrets? Adding secrets currently requires you to store your secret as a secure string in AWS Systems Manager Parameter Store (SSM), then add a reference to the SSM parameter to your manifest . We'll walk through an example where we want to store a secret called GH_WEBHOOK_SECRET with the value secretvalue1234 . First, store the secret in SSM like so: aws ssm put-parameter --name GH_WEBHOOK_SECRET --value secretvalue1234 --type SecureString \\ --tags Key = copilot-environment,Value = ${ ENVIRONMENT_NAME } Key = copilot-application,Value = ${ APP_NAME } This will store the value secretvalue1234 into the SSM parameter GH_WEBHOOK_SECRET as a secret. Attention Copilot requires the copilot-application and copilot-environment tags to limit access to this secret. It's important to replace the ${ENVIRONMENT_NAME} and ${APP_NAME} with the Copilot application and environment you want to have access to this secret. Next, we'll modify our manifest file to pass in this value: secrets : GITHUB_WEBHOOK_SECRET : GH_WEBHOOK_SECRET Once we deploy this update to our manifest, we'll be able to access the environment variable GITHUB_WEBHOOK_SECRET which will have the value of the SSM parameter GH_WEBHOOK_SECRET , secretvalue1234 . This works because ECS Agent will resolve the SSM parameter when it starts up your task, and set the environment variable for you. Info We're going to make this easier! There are a couple of caveats - you have to store the secret in the same environment as your application. Some of our next work is to add a secrets command that lets you add a secret without having to worry about which environment you're in or how SSM works.","title":"Secrets"},{"location":"docs/developing/secrets/#secrets","text":"Secrets are sensitive bits of information like OAuth tokens, secret keys or API keys - information that you need in your application code, but shouldn't commit to your source code. In the AWS Copilot CLI secrets are passed in as environment variables (read more about developing with environment variables ) but they're treated differently, due to their sensitive nature.","title":"Secrets"},{"location":"docs/developing/secrets/#how-do-i-add-secrets","text":"Adding secrets currently requires you to store your secret as a secure string in AWS Systems Manager Parameter Store (SSM), then add a reference to the SSM parameter to your manifest . We'll walk through an example where we want to store a secret called GH_WEBHOOK_SECRET with the value secretvalue1234 . First, store the secret in SSM like so: aws ssm put-parameter --name GH_WEBHOOK_SECRET --value secretvalue1234 --type SecureString \\ --tags Key = copilot-environment,Value = ${ ENVIRONMENT_NAME } Key = copilot-application,Value = ${ APP_NAME } This will store the value secretvalue1234 into the SSM parameter GH_WEBHOOK_SECRET as a secret. Attention Copilot requires the copilot-application and copilot-environment tags to limit access to this secret. It's important to replace the ${ENVIRONMENT_NAME} and ${APP_NAME} with the Copilot application and environment you want to have access to this secret. Next, we'll modify our manifest file to pass in this value: secrets : GITHUB_WEBHOOK_SECRET : GH_WEBHOOK_SECRET Once we deploy this update to our manifest, we'll be able to access the environment variable GITHUB_WEBHOOK_SECRET which will have the value of the SSM parameter GH_WEBHOOK_SECRET , secretvalue1234 . This works because ECS Agent will resolve the SSM parameter when it starts up your task, and set the environment variable for you. Info We're going to make this easier! There are a couple of caveats - you have to store the secret in the same environment as your application. Some of our next work is to add a secrets command that lets you add a secret without having to worry about which environment you're in or how SSM works.","title":"How do I add Secrets?"},{"location":"docs/developing/service-discovery/","text":"Service Discovery Service Discovery is a way of letting services discover and connect with each other. Typically, services can only talk to each other if they expose a public endpoint - and even then, requests will have to go over the internet. With ECS Service Discovery each service you create is given a private address and DNS name - meaning each service can talk to each other without ever leaving the local network (VPC) and without exposing a public endpoint. How do I use Service Discovery? Service Discovery is enabled for all services set up using the Copilot CLI. We'll show you how to use it by using an example. Imagine we have an app called kudos and two services: api and front-end . In this example we'll imagine our front-end service has a public endpoint and wants to call our api service using its service discovery endpoint. // Calling our api service from the front-end service using Service Discovery func ServiceDiscoveryGet ( w http . ResponseWriter , req * http . Request , ps httprouter . Params ) { endpoint := fmt . Sprintf ( \"http://api.%s/some-request\" , os . Getenv ( \"COPILOT_SERVICE_DISCOVERY_ENDPOINT\" )) resp , err := http . Get ( endpoint /* http://api.kudos.local/some-request */ ) if err != nil { http . Error ( w , err . Error (), http . StatusInternalServerError ) return } defer resp . Body . Close () body , _ := ioutil . ReadAll ( resp . Body ) w . WriteHeader ( http . StatusOK ) w . Write ( body ) } The important part is that our front-end service is making a request to our api service through a special endpoint: endpoint := fmt . Sprintf ( \"http://api.%s/some-request\" , os . Getenv ( \"COPILOT_SERVICE_DISCOVERY_ENDPOINT\" )) COPILOT_SERVICE_DISCOVERY_ENDPOINT is a special environment variable that the Copilot CLI sets for you when it creates your service. It's of the format {app name}.local - so in this case in our kudos app, the request would be to http://api.kudos.local/some-request . Since our api service is running on port 80, we're not specifying the port in the URL. However, if it was running on another port, say 8080, we'd need to include the port in the request, as well http://api.kudos.local:8080/some-request . When our front-end makes this request, the endpoint api.kudos.local resolves to a private IP address and is routed privately within your VPC.","title":"Service Discovery"},{"location":"docs/developing/service-discovery/#service-discovery","text":"Service Discovery is a way of letting services discover and connect with each other. Typically, services can only talk to each other if they expose a public endpoint - and even then, requests will have to go over the internet. With ECS Service Discovery each service you create is given a private address and DNS name - meaning each service can talk to each other without ever leaving the local network (VPC) and without exposing a public endpoint.","title":"Service Discovery"},{"location":"docs/developing/service-discovery/#how-do-i-use-service-discovery","text":"Service Discovery is enabled for all services set up using the Copilot CLI. We'll show you how to use it by using an example. Imagine we have an app called kudos and two services: api and front-end . In this example we'll imagine our front-end service has a public endpoint and wants to call our api service using its service discovery endpoint. // Calling our api service from the front-end service using Service Discovery func ServiceDiscoveryGet ( w http . ResponseWriter , req * http . Request , ps httprouter . Params ) { endpoint := fmt . Sprintf ( \"http://api.%s/some-request\" , os . Getenv ( \"COPILOT_SERVICE_DISCOVERY_ENDPOINT\" )) resp , err := http . Get ( endpoint /* http://api.kudos.local/some-request */ ) if err != nil { http . Error ( w , err . Error (), http . StatusInternalServerError ) return } defer resp . Body . Close () body , _ := ioutil . ReadAll ( resp . Body ) w . WriteHeader ( http . StatusOK ) w . Write ( body ) } The important part is that our front-end service is making a request to our api service through a special endpoint: endpoint := fmt . Sprintf ( \"http://api.%s/some-request\" , os . Getenv ( \"COPILOT_SERVICE_DISCOVERY_ENDPOINT\" )) COPILOT_SERVICE_DISCOVERY_ENDPOINT is a special environment variable that the Copilot CLI sets for you when it creates your service. It's of the format {app name}.local - so in this case in our kudos app, the request would be to http://api.kudos.local/some-request . Since our api service is running on port 80, we're not specifying the port in the URL. However, if it was running on another port, say 8080, we'd need to include the port in the request, as well http://api.kudos.local:8080/some-request . When our front-end makes this request, the endpoint api.kudos.local resolves to a private IP address and is routed privately within your VPC.","title":"How do I use Service Discovery?"},{"location":"docs/developing/sidecars/","text":"Sidecars Sidecars are additional containers that run along side the main container. They are usually used to perform peripheral tasks such as logging, configuration, or proxying requests. AWS also provides some plugin options that can be seamlessly incorporated with your ECS service, including but not limited to FireLens , AWS X-Ray , and AWS App Mesh . How to add sidecars with Copilot? There are two ways of adding sidecars using Copilot manifest: specify general sidecars or with sidecar patterns . General sidecars You'll need to provide the URL for the sidecar image. Optionally, you can specify the port you'd like to expose and the credential parameter for private registry . sidecars : {{ sidecar name }}: # Port of the container to expose. (Optional) port : {{ port number }} # Image URL for sidecar container. (Required) image : {{ image url }} # ARN of the secret containing the private repository credentials. (Optional) credentialParameter : {{ credential }} Below is an example of specifying the nginx sidecar container in a load balanced web service manifest. name : api type : Load Balanced Web Service image : build : api/Dockerfile port : 3000 http : path : 'api' healthcheck : '/api/health-check' # Target container for Load Balancer is our sidecar 'nginx', instead of the service container. targetContainer : 'nginx' cpu : 256 memory : 512 count : 1 sidecars : nginx : port : 80 image : 1234567890.dkr.ecr.us-west-2.amazonaws.com/reverse-proxy:revision_1 Sidecar patterns Sidecar patterns are pre-defined Copilot sidecar configurations. The only supported pattern is FireLens for now but we'll add more in the future! # In the manifest. logging : # The fluent bit image. (Optional, we'll use \"amazon/aws-for-fluent-bit:latest\" by default) image : {{ image URL }} # The configuration options to send to the Firelens log driver. (Optional) destination : {{ config key }}: {{ config value }} # Whether to include ECS metadata in logs. (Optional, default to true) enableMetadata : {{ true|false }} # Secret to pass to the log configuration. (Optional) secretOptions : {{ key }}: {{ value } # The full config file path in your custom fluent bit image. configFile : {{ config file path }} For example: logging : destination : Name : cloudwatch region : us-west-2 log_group_name : /copilot/sidecar-test-hello log_stream_prefix : copilot/ You might need to add necessary permissions to the task role so that FireLens can forward your data. You can add permissions by specifying them in your addons . For example: Resources : FireLensPolicy : Type : AWS::IAM::ManagedPolicy Properties : PolicyDocument : Version : 2012-10-17 Statement : - Effect : Allow Action : - logs:CreateLogStream - logs:CreateLogGroup - logs:DescribeLogStreams - logs:PutLogEvents Resource : \"{{ resource ARN }}\" Outputs : FireLensPolicyArn : Description : An addon ManagedPolicy gets used by the ECS task role Value : !Ref FireLensPolicy Info Since Firelens log driver can route your main container's logs to various destinations, the svc logs command can only track them when they are sent to the log group we create for Copilot service in CloudWatch. Info We're going to make this easier and more powerful! Currently we only support using remote images for sidecars which means users need to build and push their local sidecar image. But, we are planning to support using local image or Dockerfile. Additionally, Firelens will be able to route logs for the other sidecars (not just the main container).","title":"Sidecars"},{"location":"docs/developing/sidecars/#sidecars","text":"Sidecars are additional containers that run along side the main container. They are usually used to perform peripheral tasks such as logging, configuration, or proxying requests. AWS also provides some plugin options that can be seamlessly incorporated with your ECS service, including but not limited to FireLens , AWS X-Ray , and AWS App Mesh .","title":"Sidecars"},{"location":"docs/developing/sidecars/#how-to-add-sidecars-with-copilot","text":"There are two ways of adding sidecars using Copilot manifest: specify general sidecars or with sidecar patterns .","title":"How to add sidecars with Copilot?"},{"location":"docs/developing/sidecars/#general-sidecars","text":"You'll need to provide the URL for the sidecar image. Optionally, you can specify the port you'd like to expose and the credential parameter for private registry . sidecars : {{ sidecar name }}: # Port of the container to expose. (Optional) port : {{ port number }} # Image URL for sidecar container. (Required) image : {{ image url }} # ARN of the secret containing the private repository credentials. (Optional) credentialParameter : {{ credential }} Below is an example of specifying the nginx sidecar container in a load balanced web service manifest. name : api type : Load Balanced Web Service image : build : api/Dockerfile port : 3000 http : path : 'api' healthcheck : '/api/health-check' # Target container for Load Balancer is our sidecar 'nginx', instead of the service container. targetContainer : 'nginx' cpu : 256 memory : 512 count : 1 sidecars : nginx : port : 80 image : 1234567890.dkr.ecr.us-west-2.amazonaws.com/reverse-proxy:revision_1","title":"General sidecars"},{"location":"docs/developing/sidecars/#sidecar-patterns","text":"Sidecar patterns are pre-defined Copilot sidecar configurations. The only supported pattern is FireLens for now but we'll add more in the future! # In the manifest. logging : # The fluent bit image. (Optional, we'll use \"amazon/aws-for-fluent-bit:latest\" by default) image : {{ image URL }} # The configuration options to send to the Firelens log driver. (Optional) destination : {{ config key }}: {{ config value }} # Whether to include ECS metadata in logs. (Optional, default to true) enableMetadata : {{ true|false }} # Secret to pass to the log configuration. (Optional) secretOptions : {{ key }}: {{ value } # The full config file path in your custom fluent bit image. configFile : {{ config file path }} For example: logging : destination : Name : cloudwatch region : us-west-2 log_group_name : /copilot/sidecar-test-hello log_stream_prefix : copilot/ You might need to add necessary permissions to the task role so that FireLens can forward your data. You can add permissions by specifying them in your addons . For example: Resources : FireLensPolicy : Type : AWS::IAM::ManagedPolicy Properties : PolicyDocument : Version : 2012-10-17 Statement : - Effect : Allow Action : - logs:CreateLogStream - logs:CreateLogGroup - logs:DescribeLogStreams - logs:PutLogEvents Resource : \"{{ resource ARN }}\" Outputs : FireLensPolicyArn : Description : An addon ManagedPolicy gets used by the ECS task role Value : !Ref FireLensPolicy Info Since Firelens log driver can route your main container's logs to various destinations, the svc logs command can only track them when they are sent to the log group we create for Copilot service in CloudWatch. Info We're going to make this easier and more powerful! Currently we only support using remote images for sidecars which means users need to build and push their local sidecar image. But, we are planning to support using local image or Dockerfile. Additionally, Firelens will be able to route logs for the other sidecars (not just the main container).","title":"Sidecar patterns"},{"location":"docs/manifest/backend-service/","text":"List of all available properties for a 'Backend Service' manifest. # Your service name will be used in naming your resources like log groups, ECS services, etc. name : api # Your service is reachable at \"http://{{.Name}}.${COPILOT_SERVICE_DISCOVERY_ENDPOINT}:{{.Image.Port}}\" but is not public. type : Backend App image : # Path to your service's Dockerfile. build : ./api/Dockerfile # Port exposed through your container to route traffic to it. port : 8080 #Optional. Configuration for your container healthcheck. healthcheck : # The command the container runs to determine if it's healthy. command : [ \"CMD-SHELL\" , \"curl -f http://localhost:8080 || exit 1\" ] interval : 10s # Time period between healthchecks. Default is 10s if omitted. retries : 2 # Number of times to retry before container is deemed unhealthy. Default is 2 if omitted. timeout : 5s # How long to wait before considering the healthcheck failed. Default is 5s if omitted. start_period : 0s # Grace period within which to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. Default is 0s if omitted. # Number of CPU units for the task. cpu : 256 # Amount of memory in MiB used by the task. memory : 512 # Number of tasks that should be running in your service. count : 1 variables : # Optional. Pass environment variables as key value pairs. LOG_LEVEL : info secrets : # Optional. Pass secrets from AWS Systems Manager (SSM) Parameter Store. GITHUB_TOKEN : GITHUB_TOKEN # The key is the name of the environment variable, the value is the name of the SSM parameter. # Optional. You can override any of the values defined above by environment. environments : prod : count : 2 # Number of tasks to run for the \"prod\" environment. name String The name of your service. type String The architecture type for your service. Backend services is not reachable from the internet, but can be reached with service discovery from your other services. image Map The image section contains parameters relating to the Docker build configuration and exposed port. image. build String or Map If you specify a string, Copilot interprets it as the path to your Dockerfile. It will assume that the dirname of the string you specify should be the build context. The manifest: image : build : path/to/dockerfile will result in the following call to docker build: $ docker build --file path/to/dockerfile path/to You can also specify build as a map: image : build : dockerfile : path/to/dockerfile context : context/dir args : key : value In this case, copilot will use the context directory you specified and convert the key-value pairs under args to --build-arg overrides. The equivalent docker build call will be: $ docker build --file path/to/dockerfile --build-arg key=value context/dir . You can omit fields and Copilot will do its best to understand what you mean. For example, if you specify context but not dockerfile , Copilot will run Docker in the context directory and assume that your Dockerfile is named \"Dockerfile.\" If you specify dockerfile but no context , Copilot assumes you want to run Docker in the directory that contains dockerfile . All paths are relative to your workspace root. image. port Integer The port exposed in your Dockerfile. Copilot should parse this value for you from your EXPOSE instruction. image. healthcheck Map Optional configuration for container health checks. image.healthcheck. command Array of Strings The command to run to determine if the container is healthy. The string array can start with CMD to execute the command arguments directly, or CMD-SHELL to run the command with the container's default shell. image.healthcheck. interval Duration Time period between healthchecks in seconds. Default is 10s. image.healthcheck. retries Integer Number of times to retry before container is deemed unhealthy. Default is 2. image.healthcheck. timeout Duration How long to wait before considering the healthcheck failed in seconds. Default is 5s. image.healthcheck. start_period Duration Grace period within which to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. Default is 0s. cpu Integer Number of CPU units for the task. See the Amazon ECS docs for valid CPU values. memory Integer Amount of memory in MiB used by the task. See the Amazon ECS docs for valid memory values. count Integer or Map If you specify a number: count : 5 The service will set the desired count to 5 and maintain 5 tasks in your service. Alternatively, you can specify a map for setting up autoscaling: count : range : 1-10 cpu_percentage : 70 memory_percentage : 80 count. range String Specify a minimum and maximum bound for the number of tasks your service should maintain. count. cpu_percentage Integer Scale up or down based on the average CPU your service should maintain. count. memory_percentage Integer Scale up or down based on the average memory your service should maintain. variables Map Key-value pairs that represents environment variables that will be passed to your service. Copilot will include a number of environment variables by default for you. secrets Map Key-value pairs that represents secret values from AWS Systems Manager Parameter Store that will passed to your service as environment variables securely. environments Map The environment section lets you overwrite any value in your manifest based on the environment you're in. In the example manifest above, we're overriding the count parameter so that we can run 2 copies of our service in our prod environment.","title":"Backend Service"},{"location":"docs/manifest/lb-web-service/","text":"List of all available properties for a 'Load Balanced Web Service' manifest. # Your service name will be used in naming your resources like log groups, ECS services, etc. name : frontend # The \"architecture\" of the service you're running. type : Load Balanced Web Service image : # Path to your service's Dockerfile. build : ./Dockerfile # Port exposed through your container to route traffic to it. port : 80 http : # Requests to this path will be forwarded to your service. # To match all requests you can use the \"/\" path. path : '/' # You can specify a custom health check path. The default is \"/\" # healthcheck: \"/\" # You can specify whether to enable sticky sessions. # stickiness: true # Number of CPU units for the task. cpu : 256 # Amount of memory in MiB used by the task. memory : 512 # Number of tasks that should be running in your service. You can also specify a map for autoscaling. count : 1 variables : # Optional. Pass environment variables as key value pairs. LOG_LEVEL : info secrets : # Optional. Pass secrets from AWS Systems Manager (SSM) Parameter Store. GITHUB_TOKEN : GITHUB_TOKEN # The key is the name of the environment variable, the value is the name of the SSM parameter. # Optional. You can override any of the values defined above by environment. environments : test : count : 2 # Number of tasks to run for the \"test\" environment. name String The name of your service. type String The architecture type for your service. A Load balanced web service is an internet-facing service that's behind a load balancer, orchestrated by Amazon ECS on AWS Fargate. image Map The image section contains parameters relating to the Docker build configuration and exposed port. image. build String or Map If you specify a string, Copilot interprets it as the path to your Dockerfile. It will assume that the dirname of the string you specify should be the build context. The manifest: image : build : path/to/dockerfile will result in the following call to docker build: $ docker build --file path/to/dockerfile path/to You can also specify build as a map: image : build : dockerfile : path/to/dockerfile context : context/dir args : key : value In this case, copilot will use the context directory you specified and convert the key-value pairs under args to --build-arg overrides. The equivalent docker build call will be: $ docker build --file path/to/dockerfile --build-arg key=value context/dir . You can omit fields and Copilot will do its best to understand what you mean. For example, if you specify context but not dockerfile , Copilot will run Docker in the context directory and assume that your Dockerfile is named \"Dockerfile.\" If you specify dockerfile but no context , Copilot assumes you want to run Docker in the directory that contains dockerfile . All paths are relative to your workspace root. image. port Integer The port exposed in your Dockerfile. Copilot should parse this value for you from your EXPOSE instruction. http Map The http section contains parameters related to integrating your service with an Application Load Balancer. http. path String Requests to this path will be forwarded to your service. Each Load Balanced Web Service should listen on a unique path. http. healthcheck String Path exposed in your container to handle target group health check requests. http. stickiness Boolean Indicates whether sticky sessions are enabled. cpu Integer Number of CPU units for the task. See the Amazon ECS docs for valid CPU values. memory Integer Amount of memory in MiB used by the task. See the Amazon ECS docs for valid memory values. count Integer or Map If you specify a number: count : 5 The service will set the desired count to 5 and maintain 5 tasks in your service. Alternatively, you can specify a map for setting up autoscaling: count : range : 1-10 cpu_percentage : 70 memory_percentage : 80 count. range String Specify a minimum and maximum bound for the number of tasks your service should maintain. count. cpu_percentage Integer Scale up or down based on the average CPU your service should maintain. count. memory_percentage Integer Scale up or down based on the average memory your service should maintain. variables Map Key-value pairs that represents environment variables that will be passed to your service. Copilot will include a number of environment variables by default for you. secrets Map Key-value pairs that represents secret values from AWS Systems Manager Parameter Store that will passed to your service as environment variables securely. environments Map The environment section lets you overwrite any value in your manifest based on the environment you're in. In the example manifest above, we're overriding the count parameter so that we can run 2 copies of our service in our prod environment.","title":"Load Balanced Web Service"},{"location":"docs/manifest/overview/","text":"Manifest The AWS Copilot CLI manifests describe a service\u2019s architecture as infrastructure-as-code. It is a file generated from copilot init or copilot svc init that gets converted to a AWS CloudFormation template. Unlike raw CloudFormation templates, the manifest allows you to focus on the most common settings for the architecture of your service and not the individual resources. Manifest files are stored under copilot/<your service name>/manifest.yml .","title":"Overview"},{"location":"docs/manifest/overview/#manifest","text":"The AWS Copilot CLI manifests describe a service\u2019s architecture as infrastructure-as-code. It is a file generated from copilot init or copilot svc init that gets converted to a AWS CloudFormation template. Unlike raw CloudFormation templates, the manifest allows you to focus on the most common settings for the architecture of your service and not the individual resources. Manifest files are stored under copilot/<your service name>/manifest.yml .","title":"Manifest"},{"location":"docs/manifest/pipeline/","text":"List of all available properties for a Copilot pipeline manifest. # This YAML file defines the relationship and deployment ordering of your environments. # The name of the pipeline name : pipeline-sample-app-frontend # The version of the schema used in this template version : 1 # This section defines the source artifacts. source : # The name of the provider that is used to store the source artifacts. provider : GitHub # Additional properties that further specifies the exact location # the artifacts should be sourced from. For example, the GitHub provider # has the following properties: repository, branch. properties : access_token_secret : github-token-sample-app branch : master repository : https://github.com/<user>/sample-app-frontend # The deployment section defines the order the pipeline will deploy # to your environments. stages : - # The name of the environment to deploy to. name : test # Use test commands to validate your stage's deployment. test_commands : - make test - echo \"woo! Tests passed\" - # The name of the environment to deploy to. name : prod # Require a manual approval step before deployment. requires_approval : true name String The name of your pipeline. version String The schema version for the template. There is only one version 1 supported at the moment. source Map Configuration for how your pipeline is triggered. source. provider String The name of your provider. Currently, only \"GitHub\" is supported. source. properties Map Provider-specific configuration on how the pipeline is triggered. source.properties. access_token_secret String The name of AWS Secrets Manager secret that holds the GitHub access token to trigger the pipeline. source.properties. branch String The name of the branch from your repository to trigger the pipeline from. source.properties. repository String The URL to your repository. stages Array of Maps Ordered list of environments that your pipeline will deploy to. stage. name String The name of the environment to deploy your services to. stage. requires_approval Boolean Indicates whether to add a manual approval step before the deployment. stage. test_commands Array of Strings Commands to run integration or end-to-end tests after deployment.","title":"Pipeline"}]}